2022-01-17T14:00:30,620 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:00:30,620 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:00:30,712 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:00:30,712 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:00:31,009 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: N/A
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:00:31,009 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: N/A
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:00:31,044 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:00:31,044 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:00:31,310 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:00:31,310 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:00:31,311 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:00:31,311 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:00:31,313 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:00:31,313 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:00:31,316 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:00:31,316 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:00:31,322 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:00:31,322 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:00:32,126 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642424432
2022-01-17T14:00:32,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:75.91707611083984|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642424432
2022-01-17T14:00:32,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:370.7694435119629|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642424432
2022-01-17T14:00:32,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:83.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642424432
2022-01-17T14:00:32,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:499.890625|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642424432
2022-01-17T14:00:32,149 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7574.8671875|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642424432
2022-01-17T14:00:32,150 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:93.8|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642424432
2022-01-17T14:00:50,239 [INFO ] nioEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-17T14:00:50,240 [INFO ] nioEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-17T14:00:50,239 [INFO ] nioEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-17T14:00:50,296 [INFO ] nioEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-17T14:00:50,240 [INFO ] nioEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-17T14:00:50,296 [INFO ] nioEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-17T14:35:07,571 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:35:07,571 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:35:07,864 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: my_fancy_model=my_fancy_model.mar
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:35:07,864 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: my_fancy_model=my_fancy_model.mar
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:35:07,886 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:35:07,886 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:35:07,930 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: my_fancy_model.mar
2022-01-17T14:35:07,930 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: my_fancy_model.mar
2022-01-17T14:35:09,456 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_fancy_model
2022-01-17T14:35:09,456 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_fancy_model
2022-01-17T14:35:09,457 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_fancy_model
2022-01-17T14:35:09,457 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_fancy_model
2022-01-17T14:35:09,458 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_fancy_model loaded.
2022-01-17T14:35:09,458 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_fancy_model loaded.
2022-01-17T14:35:09,459 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_fancy_model, count: 4
2022-01-17T14:35:09,459 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_fancy_model, count: 4
2022-01-17T14:35:09,481 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:09,483 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:09,481 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:09,495 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:09,483 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:09,501 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:35:09,506 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:09,506 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:09,495 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:09,501 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:35:09,993 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:35:09,993 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:35:09,994 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:35:09,994 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:35:09,996 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:35:09,996 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:35:10,017 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:35:10,017 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:35:10,061 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:35:10,061 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:35:11,126 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-17T14:35:11,126 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-17T14:35:11,773 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426511
2022-01-17T14:35:11,778 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:75.46057510375977|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426511
2022-01-17T14:35:11,779 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:371.22594451904297|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426511
2022-01-17T14:35:11,779 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:83.1|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426511
2022-01-17T14:35:11,780 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:863.21484375|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426511
2022-01-17T14:35:11,781 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7211.54296875|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426511
2022-01-17T14:35:11,781 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:89.3|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426511
2022-01-17T14:35:13,702 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:13,703 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]20748
2022-01-17T14:35:13,704 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:13,705 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:13,705 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:35:13,705 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:35:13,713 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:13,713 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:13,740 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:35:13,745 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426513745
2022-01-17T14:35:13,745 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426513745
2022-01-17T14:35:13,794 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:13,909 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:13,911 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]15288
2022-01-17T14:35:13,912 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:35:13,912 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:13,912 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:35:13,914 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:13,914 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:13,918 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426513918
2022-01-17T14:35:13,918 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426513918
2022-01-17T14:35:13,942 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:13,943 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:35:13,944 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:14,138 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:14,153 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]18536
2022-01-17T14:35:14,153 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:14,154 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:35:14,154 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:14,154 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:35:14,178 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:14,178 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:14,197 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426514197
2022-01-17T14:35:14,197 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:35:14,197 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426514197
2022-01-17T14:35:14,227 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:14,263 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:14,264 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:14,265 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:14,266 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:14,265 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:14,266 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:14,267 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:14,268 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:14,269 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:14,269 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:14,270 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:14,271 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:14,271 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:14,272 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:14,272 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:14,273 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:14,273 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:14,274 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:14,274 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:14,274 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:14,275 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:14,275 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:14,276 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:14,276 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:14,277 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:14,277 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:14,278 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:14,278 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:14,279 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:14,280 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:14,281 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:14,281 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:14,281 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:14,282 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:14,283 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:14,283 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:14,284 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:14,284 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:14,285 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:14,285 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:14,286 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:14,287 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:14,287 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:14,288 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:14,274 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:14,289 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:14,289 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:14,307 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:14,307 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:14,308 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:14,308 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:14,309 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,309 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,309 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,309 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,310 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:35:14,310 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:35:14,323 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,323 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,323 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,323 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,517 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:14,519 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]8992
2022-01-17T14:35:14,520 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:35:14,520 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:14,520 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:35:14,524 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:14,525 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:14,525 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:14,530 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:35:14,530 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426514530
2022-01-17T14:35:14,530 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426514530
2022-01-17T14:35:14,580 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:14,643 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:14,644 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:14,643 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:14,644 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:14,658 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:14,643 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:14,661 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:14,643 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:14,658 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:14,654 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:14,663 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:14,664 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:14,665 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:14,664 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:14,665 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:14,666 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:14,667 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:14,668 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:14,669 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:14,669 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:14,670 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:14,671 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:14,671 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:14,672 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:14,672 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:14,673 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:14,673 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:14,673 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:14,674 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:14,674 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:14,675 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:14,675 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:14,676 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:14,676 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:14,677 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:14,677 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:14,661 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:14,679 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:14,664 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:14,664 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:14,681 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:14,681 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:14,685 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:14,679 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:14,679 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:14,687 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:14,685 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:14,681 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:14,687 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,687 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:14,687 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:14,687 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,687 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:14,688 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:14,702 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,702 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:14,687 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:14,703 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:14,703 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:14,704 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:14,704 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:14,705 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:14,705 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:14,703 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:14,703 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:14,706 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:14,707 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:14,706 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:14,708 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:14,702 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,709 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:35:14,707 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:14,713 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,713 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,710 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:14,725 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,725 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,703 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:14,709 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:14,731 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:14,731 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:14,732 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:14,732 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:14,733 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:14,733 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:14,734 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:14,731 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,734 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:14,735 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:14,735 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:14,736 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:14,736 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:14,736 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:14,737 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:14,737 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:14,709 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:35:14,731 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,771 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,771 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,786 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:35:14,771 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:14,786 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,786 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:35:14,789 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:14,786 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:14,789 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:15,055 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:15,055 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:15,055 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:15,055 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:15,055 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:15,056 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:15,057 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:15,057 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:15,057 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:15,057 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:15,058 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:15,058 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:15,058 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:15,064 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:15,065 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:15,058 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:15,066 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:15,065 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:15,066 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:15,066 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:15,067 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:15,068 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:15,068 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:15,069 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:15,069 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:15,069 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:15,070 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:15,070 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:15,070 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:15,071 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:15,071 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:15,071 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:15,072 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:15,072 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:15,073 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:15,068 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:15,074 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:15,078 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:15,077 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:15,078 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:15,081 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:15,078 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:15,081 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:15,081 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:15,088 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:15,089 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:15,089 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:35:15,089 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:15,089 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:35:15,098 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:15,098 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:15,328 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:15,328 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:15,724 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:15,724 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:15,788 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:15,788 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:16,099 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:16,099 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:18,439 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:18,442 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]13500
2022-01-17T14:35:18,445 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:18,445 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:18,446 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:18,445 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:18,449 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:18,449 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:18,453 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426518453
2022-01-17T14:35:18,453 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:35:18,453 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426518453
2022-01-17T14:35:18,499 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:18,853 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:18,853 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:18,853 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:18,854 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:18,856 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:18,857 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:18,857 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:18,857 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:18,858 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:18,858 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:18,858 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:18,859 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:18,859 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:18,860 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:18,860 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:18,861 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:18,861 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:18,862 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:18,862 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:18,862 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:18,863 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:18,863 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:18,863 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:18,864 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:18,864 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:18,864 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:18,865 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:18,865 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:18,865 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:18,867 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:18,867 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:18,868 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:18,868 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:18,869 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:18,869 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:18,870 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:18,870 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:18,870 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:18,871 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:18,871 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:18,872 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:18,857 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:18,872 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:18,872 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:18,873 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:18,875 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:18,875 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:18,875 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:18,879 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:18,880 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:18,880 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:18,886 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:18,886 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:18,891 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:18,891 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:18,896 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:35:18,904 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:18,904 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:18,896 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:35:18,904 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:18,904 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:18,922 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:18,923 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]11200
2022-01-17T14:35:18,923 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:18,923 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:18,923 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:18,923 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:18,924 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:18,924 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:18,926 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426518926
2022-01-17T14:35:18,926 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:35:18,926 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426518926
2022-01-17T14:35:18,943 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:18,999 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:19,000 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]23332
2022-01-17T14:35:19,000 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:19,000 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:19,001 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:19,001 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:19,002 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:19,002 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:19,005 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426519005
2022-01-17T14:35:19,005 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:35:19,005 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426519005
2022-01-17T14:35:19,019 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:19,304 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:19,304 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:19,304 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:19,306 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:19,306 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:19,306 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:19,306 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:19,307 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:19,307 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:19,307 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:19,308 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:19,308 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:19,309 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:19,309 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:19,309 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:19,310 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:19,310 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:19,311 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:19,311 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:19,311 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:19,312 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:19,312 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:19,313 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:19,313 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:19,313 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:19,314 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:19,314 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:19,315 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:19,315 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:19,317 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:19,317 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:19,318 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:19,318 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:19,318 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:19,319 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:19,319 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:19,319 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:19,320 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:19,320 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:19,321 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:19,321 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:19,322 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:19,323 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:19,323 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:19,306 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:19,325 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:19,325 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:19,339 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:19,339 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:19,342 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:19,342 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:19,350 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:19,350 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:19,355 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:19,358 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:19,358 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:19,355 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:19,358 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:19,358 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:19,362 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:35:19,362 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:35:19,365 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:19,366 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:19,366 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:19,366 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:19,366 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:19,367 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:19,367 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:19,368 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:19,368 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:19,369 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:19,369 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:19,367 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:19,370 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:19,374 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:19,375 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:19,375 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:19,375 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:19,376 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:19,376 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:19,377 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:19,377 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:19,377 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:19,378 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:19,378 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:19,378 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:19,379 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:19,379 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:19,379 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:19,380 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:19,380 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:19,374 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:19,382 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:19,374 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:19,383 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:19,383 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:19,383 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:19,384 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:19,396 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:19,396 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:19,396 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:19,397 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:19,397 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:19,397 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:19,398 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:19,397 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:19,398 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:19,398 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:19,398 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:19,399 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:19,399 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:19,399 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:19,399 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:35:19,399 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:19,400 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:19,399 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:35:19,400 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:19,404 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:19,404 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:19,653 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:19,654 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]5492
2022-01-17T14:35:19,655 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:19,655 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:19,655 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:19,655 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:19,656 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:19,656 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:19,658 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426519658
2022-01-17T14:35:19,658 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:35:19,658 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426519658
2022-01-17T14:35:19,694 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:19,900 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:19,900 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:19,987 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:19,987 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:19,987 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:19,988 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:19,989 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:19,989 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:19,989 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:19,990 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:19,990 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:19,990 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:19,991 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:19,991 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:19,992 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:19,992 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:19,992 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:19,993 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:19,993 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:19,993 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:19,994 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:19,994 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:19,994 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:19,994 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:19,995 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:19,995 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:19,995 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:19,996 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:19,996 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:19,996 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:19,997 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:19,998 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:19,999 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:19,999 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:20,000 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:20,000 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:20,001 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:20,001 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:20,002 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:20,002 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:20,003 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:20,003 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:20,003 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:20,004 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:20,005 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:20,005 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:19,994 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:20,029 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:20,029 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:20,036 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:20,036 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:20,038 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:20,038 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:20,041 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:20,041 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:20,042 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:20,042 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:20,043 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:35:20,045 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:20,045 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:20,043 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:35:20,045 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:20,045 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:20,375 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:20,375 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:20,407 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:20,407 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:21,055 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:21,055 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:22,996 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:22,998 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]5172
2022-01-17T14:35:23,001 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:23,001 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:23,004 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:23,001 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:23,010 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:23,010 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:23,022 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426523022
2022-01-17T14:35:23,022 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:35:23,022 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426523022
2022-01-17T14:35:23,034 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:23,377 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:23,377 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:23,377 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:23,382 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:23,379 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:23,384 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:23,386 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:23,386 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:23,387 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:23,387 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:23,387 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:23,388 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:23,388 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:23,389 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:23,389 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:23,389 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:23,390 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:23,390 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:23,391 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:23,391 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:23,392 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:23,392 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:23,392 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:23,393 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:23,393 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:23,394 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:23,394 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:23,394 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:23,395 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:23,396 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:23,397 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:23,397 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:23,397 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:23,398 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:23,398 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:23,399 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:23,400 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:23,400 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:23,401 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:23,401 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:23,402 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:23,403 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:23,403 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:23,403 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:23,382 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:23,420 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:23,420 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:23,425 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:23,425 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:23,432 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:23,432 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:23,436 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,436 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,437 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,437 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,439 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-01-17T14:35:23,439 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-01-17T14:35:23,442 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,442 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,442 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,442 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,458 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:23,459 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]20928
2022-01-17T14:35:23,460 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:23,459 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:23,460 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:23,460 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:23,463 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:23,463 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:23,477 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426523477
2022-01-17T14:35:23,477 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426523477
2022-01-17T14:35:23,477 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:35:23,478 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:23,480 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:23,481 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]3264
2022-01-17T14:35:23,482 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:23,482 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:23,482 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:23,483 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:23,482 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:23,483 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:23,488 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426523488
2022-01-17T14:35:23,487 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:35:23,488 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426523488
2022-01-17T14:35:23,489 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:23,759 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:23,760 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:23,760 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:23,761 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:23,761 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:23,761 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:23,761 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:23,762 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:23,762 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:23,762 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:23,762 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:23,763 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:23,763 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:23,763 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:23,763 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:23,764 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:23,763 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:23,764 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:23,771 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:23,772 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:23,772 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:23,772 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:23,773 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:23,773 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:23,773 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:23,774 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:23,774 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:23,774 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:23,774 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:23,775 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:23,776 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:23,771 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:23,777 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:23,777 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:23,778 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:23,778 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:23,778 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:23,779 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:23,779 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:23,779 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:23,780 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:23,780 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:23,781 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:23,780 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:23,771 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:23,781 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:23,780 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:23,781 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:23,787 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:23,787 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:23,788 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:23,788 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:23,793 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:23,787 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:23,793 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:23,789 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:23,789 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:23,818 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:23,818 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:23,818 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:23,827 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,818 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:23,827 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,818 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:23,832 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:23,830 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:23,832 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,832 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:23,837 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,837 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,832 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:23,837 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,837 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,832 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:23,841 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:23,841 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:23,849 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,832 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,849 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-17T14:35:23,849 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-17T14:35:23,841 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:23,849 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,851 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,851 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,857 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-01-17T14:35:23,851 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:23,857 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,857 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-01-17T14:35:23,857 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:23,860 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:23,860 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:24,504 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:24,505 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]14936
2022-01-17T14:35:24,505 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:24,505 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:24,506 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:24,505 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:24,507 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:24,507 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:24,510 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426524509
2022-01-17T14:35:24,509 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:35:24,510 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426524509
2022-01-17T14:35:24,511 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:24,755 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:24,756 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:24,756 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:24,756 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:24,756 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:24,757 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:24,757 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:24,757 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:24,757 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:24,758 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:24,758 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:24,758 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:24,759 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:24,759 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:24,759 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:24,760 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:24,760 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:24,760 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:24,761 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:24,761 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:24,761 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:24,761 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:24,762 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:24,762 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:24,762 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:24,762 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:24,763 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:24,763 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:24,763 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:24,764 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:24,757 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:24,775 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:24,757 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:24,779 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:24,779 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:24,779 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:24,779 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:24,780 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:24,780 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:24,780 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:24,781 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:24,781 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:24,781 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:24,782 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:24,782 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:24,779 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:24,783 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:24,783 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:24,784 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:24,784 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:24,784 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:24,786 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:24,786 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:24,787 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:24,787 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:24,787 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-17T14:35:24,787 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-17T14:35:24,790 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:24,790 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:24,790 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:24,790 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:25,452 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:25,452 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:25,863 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:25,863 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:25,863 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:25,863 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:26,789 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:26,789 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:28,337 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:28,338 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]19708
2022-01-17T14:35:28,339 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:28,340 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:28,340 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:28,360 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:28,362 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:28,362 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:28,389 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426528389
2022-01-17T14:35:28,389 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:35:28,389 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426528389
2022-01-17T14:35:28,391 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:28,765 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:28,765 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:28,766 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:28,766 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:28,766 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:28,767 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:28,767 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:28,767 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:28,768 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:28,768 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:28,769 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:28,769 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:28,769 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:28,770 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:28,770 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:28,770 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:28,771 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:28,771 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:28,771 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:28,772 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:28,772 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:28,772 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:28,772 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:28,773 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:28,773 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:28,773 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:28,774 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:28,774 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:28,774 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:28,775 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:28,775 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:28,775 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:28,776 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:28,776 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:28,776 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:28,777 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:28,777 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:28,778 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:28,778 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:28,778 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:28,779 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:28,792 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:28,792 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:28,793 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:28,793 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:28,794 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:28,794 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:28,798 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:28,798 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:28,799 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:28,799 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:28,800 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:28,800 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:28,801 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:28,801 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:28,802 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-01-17T14:35:28,802 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-01-17T14:35:28,807 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:28,807 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:28,807 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:28,807 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:28,909 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:28,910 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21160
2022-01-17T14:35:28,911 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:28,911 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:28,911 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:28,911 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:28,912 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:28,912 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:28,913 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426528913
2022-01-17T14:35:28,913 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:35:28,913 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426528913
2022-01-17T14:35:28,915 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:28,934 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:28,935 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]16836
2022-01-17T14:35:28,935 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:28,936 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:28,936 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:28,936 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:28,938 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:28,938 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:28,940 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:35:28,940 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426528940
2022-01-17T14:35:28,940 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426528940
2022-01-17T14:35:28,942 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:29,200 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:29,201 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:29,201 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:29,201 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:29,204 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:29,204 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:29,205 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:29,205 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:29,205 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:29,206 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:29,206 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:29,206 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:29,207 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:29,207 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:29,207 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:29,207 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:29,208 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:29,208 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:29,208 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:29,208 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:29,209 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:29,209 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:29,209 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:29,210 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:29,210 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:29,210 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:29,210 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:29,211 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:29,211 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:29,211 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:29,212 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:29,212 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:29,212 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:29,213 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:29,213 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:29,213 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:29,214 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:29,214 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:29,214 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:29,215 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:29,215 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:29,215 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:29,216 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:29,216 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:29,216 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:29,222 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:29,222 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:29,237 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:29,274 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:29,237 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:29,274 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:29,277 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:29,277 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:29,274 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:29,278 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:29,278 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:29,278 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:29,279 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:29,279 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:29,279 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:29,279 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:29,280 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:29,280 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:29,281 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:29,281 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:29,281 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:29,282 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:29,282 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:29,282 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:29,282 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:29,283 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:29,283 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:29,283 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:29,284 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:29,284 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:29,277 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:29,284 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:29,277 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:29,284 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:29,307 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:29,284 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:29,308 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:29,307 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:29,308 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:29,310 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:29,308 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:29,311 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:29,310 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:29,311 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:29,313 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-01-17T14:35:29,311 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:29,313 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-01-17T14:35:29,313 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:29,313 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:29,314 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:29,314 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:29,314 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:29,314 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:29,315 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:29,314 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:29,316 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:29,316 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:29,315 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:29,316 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:29,316 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:29,317 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:29,318 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:29,318 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:29,319 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:29,319 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:29,319 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:29,319 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:29,320 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:29,322 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:29,322 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-01-17T14:35:29,322 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:29,322 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-01-17T14:35:29,331 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:29,331 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:30,138 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:30,139 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]9904
2022-01-17T14:35:30,139 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:30,140 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:30,140 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:30,140 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:30,140 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:30,141 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:30,142 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426530142
2022-01-17T14:35:30,142 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:35:30,142 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426530142
2022-01-17T14:35:30,146 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:30,409 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:30,409 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:30,409 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:30,409 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:30,410 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:30,410 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:30,410 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:30,411 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:30,411 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:30,411 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:30,412 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:30,412 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:30,412 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:30,413 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:30,413 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:30,413 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:30,414 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:30,414 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:30,414 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:30,414 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:30,415 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:30,415 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:30,415 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:30,415 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:30,416 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:30,416 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:30,416 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:30,417 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:30,417 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:30,418 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:30,418 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:30,418 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:30,419 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:30,419 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:30,419 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:30,420 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:30,420 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:30,420 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:30,421 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:30,421 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:30,421 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:30,422 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:30,422 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:30,422 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:30,410 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:30,423 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:30,423 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:30,430 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:30,430 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:30,436 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:30,436 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:30,437 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:30,437 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:30,438 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:30,438 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:30,439 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-17T14:35:30,439 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-17T14:35:30,441 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:30,441 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:30,441 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:30,441 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:31,813 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:31,813 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:32,319 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:32,319 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:32,338 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:32,338 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:33,445 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:33,445 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:34,704 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:34,705 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]3112
2022-01-17T14:35:34,705 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:34,705 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:34,705 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:34,705 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:34,714 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:34,714 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:34,716 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426534716
2022-01-17T14:35:34,716 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:35:34,716 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426534716
2022-01-17T14:35:34,721 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:35,069 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:35,070 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:35,070 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:35,070 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:35,070 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:35,070 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:35,070 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:35,071 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:35,071 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:35,071 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:35,072 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:35,072 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:35,072 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:35,073 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:35,073 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:35,073 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:35,074 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:35,074 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:35,074 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:35,074 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:35,075 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:35,076 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:35,076 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:35,077 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:35,077 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:35,077 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:35,078 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:35,078 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:35,078 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:35,079 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:35,079 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:35,079 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:35,080 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:35,080 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:35,080 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:35,081 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:35,081 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:35,081 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:35,081 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:35,082 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:35,082 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:35,082 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:35,083 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:35,083 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:35,070 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:35,101 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:35,101 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:35,118 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:35,118 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:35,160 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:35,160 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:35,168 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,168 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,188 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,215 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,215 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,188 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,215 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,215 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,216 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-01-17T14:35:35,216 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-01-17T14:35:35,383 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:35,384 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]5416
2022-01-17T14:35:35,384 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:35,384 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:35,385 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:35,385 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:35,386 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:35,386 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:35,392 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426535392
2022-01-17T14:35:35,392 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:35:35,392 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426535392
2022-01-17T14:35:35,393 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:35,559 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:35,560 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22580
2022-01-17T14:35:35,560 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:35,560 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:35,561 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:35,560 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:35,562 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:35,562 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:35,564 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426535564
2022-01-17T14:35:35,564 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:35:35,564 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426535564
2022-01-17T14:35:35,566 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:35,711 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:35,711 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:35,711 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:35,711 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:35,712 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:35,712 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:35,712 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:35,713 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:35,713 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:35,713 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:35,714 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:35,714 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:35,714 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:35,715 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:35,715 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:35,715 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:35,716 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:35,716 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:35,716 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:35,716 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:35,717 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:35,717 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:35,718 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:35,718 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:35,718 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:35,718 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:35,719 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:35,719 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:35,720 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:35,720 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:35,720 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:35,721 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:35,721 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:35,721 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:35,722 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:35,722 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:35,722 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:35,723 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:35,723 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:35,723 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:35,723 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:35,724 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:35,724 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:35,724 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:35,712 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:35,725 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:35,725 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:35,740 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:35,740 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:35,746 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:35,746 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:35,748 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,748 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,750 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,750 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,754 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-01-17T14:35:35,754 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-01-17T14:35:35,757 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,757 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,757 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,757 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,882 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:35,883 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:35,883 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:35,883 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:35,883 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:35,883 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:35,884 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:35,884 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:35,885 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:35,885 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:35,886 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:35,886 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:35,886 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:35,887 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:35,887 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:35,887 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:35,887 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:35,888 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:35,888 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:35,888 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:35,888 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:35,889 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:35,889 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:35,889 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:35,890 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:35,890 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:35,890 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:35,891 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:35,891 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:35,891 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:35,892 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:35,892 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:35,892 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:35,893 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:35,893 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:35,893 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:35,894 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:35,894 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:35,894 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:35,895 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:35,895 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:35,895 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:35,896 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:35,896 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:35,884 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:35,902 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:35,902 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:35,905 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:35,905 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:35,910 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:35,910 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:35,911 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,911 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,912 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,912 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,913 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-01-17T14:35:35,913 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-01-17T14:35:35,914 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,914 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:35,914 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:35,914 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:36,758 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:36,759 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]23536
2022-01-17T14:35:36,760 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:36,760 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:36,760 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:36,760 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:36,761 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:36,761 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:36,762 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426536762
2022-01-17T14:35:36,762 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426536762
2022-01-17T14:35:36,762 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:35:36,764 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:37,019 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:37,018 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:37,019 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:37,019 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:37,020 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:37,020 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:37,020 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:37,021 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:37,021 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:37,021 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:37,022 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:37,022 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:37,022 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:37,023 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:37,023 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:37,023 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:37,023 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:37,024 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:37,024 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:37,024 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:37,024 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:37,025 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:37,025 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:37,025 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:37,025 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:37,026 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:37,026 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:37,026 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:37,027 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:37,027 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:37,027 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:37,028 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:37,028 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:37,028 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:37,029 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:37,029 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:37,029 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:37,030 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:37,030 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:37,030 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:37,031 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:37,031 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:37,031 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:37,031 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:37,020 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:37,035 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:37,035 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:37,038 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:37,038 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:37,040 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:37,040 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:37,043 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:37,043 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:37,043 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:37,043 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:37,044 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-17T14:35:37,044 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-17T14:35:37,046 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:37,046 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:37,046 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:37,046 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:40,226 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:40,226 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:40,764 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:40,764 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:40,923 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:40,923 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:42,054 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:42,054 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:43,118 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:43,119 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]11440
2022-01-17T14:35:43,120 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:43,119 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:43,120 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:43,120 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:43,121 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:43,121 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:43,122 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426543122
2022-01-17T14:35:43,122 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:35:43,122 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426543122
2022-01-17T14:35:43,143 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:43,517 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:43,516 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:43,517 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:43,519 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:43,520 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:43,520 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:43,520 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:43,521 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:43,521 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:43,521 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:43,522 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:43,522 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:43,522 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:43,523 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:43,523 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:43,523 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:43,523 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:43,524 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:43,524 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:43,524 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:43,524 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:43,525 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:43,525 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:43,525 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:43,526 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:43,526 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:43,526 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:43,526 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:43,527 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:43,527 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:43,527 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:43,528 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:43,528 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:43,528 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:43,529 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:43,529 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:43,529 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:43,530 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:43,530 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:43,531 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:43,531 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:43,531 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:43,532 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:43,532 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:43,520 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:43,534 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:43,534 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:43,538 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:43,538 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:43,545 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:43,545 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:43,546 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:43,546 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:43,547 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:43,547 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:43,548 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-01-17T14:35:43,548 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-01-17T14:35:43,570 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:43,570 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:43,570 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:43,570 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:43,799 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:43,800 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]19180
2022-01-17T14:35:43,800 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:43,800 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:43,800 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:43,800 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:43,801 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:43,801 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:43,803 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426543803
2022-01-17T14:35:43,803 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:35:43,803 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426543803
2022-01-17T14:35:43,805 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:43,865 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:43,866 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]17496
2022-01-17T14:35:43,866 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:43,866 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:43,866 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:43,866 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:43,868 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:43,868 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:43,870 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426543870
2022-01-17T14:35:43,870 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:35:43,870 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426543870
2022-01-17T14:35:43,872 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:44,110 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:44,109 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:44,110 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:44,110 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:44,111 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:44,111 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:44,111 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:44,111 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:44,112 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:44,112 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:44,112 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:44,113 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:44,113 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:44,113 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:44,114 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:44,114 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:44,114 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:44,115 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:44,115 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:44,115 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:44,116 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:44,116 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:44,116 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:44,117 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:44,117 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:44,117 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:44,118 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:44,118 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:44,118 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:44,119 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:44,119 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:44,119 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:44,120 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:44,120 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:44,120 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:44,121 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:44,121 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:44,121 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:44,122 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:44,122 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:44,122 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:44,123 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:44,123 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:44,123 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:44,111 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:44,124 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:44,124 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:44,144 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:44,144 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:44,153 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:44,153 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:44,161 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:44,161 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:44,165 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:44,165 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:44,174 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-01-17T14:35:44,174 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-01-17T14:35:44,176 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:44,176 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:44,176 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:44,176 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:44,227 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:44,228 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:44,228 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:44,228 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:44,228 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:44,229 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:44,229 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:44,229 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:44,229 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:44,230 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:44,230 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:44,230 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:44,231 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:44,231 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:44,231 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:44,231 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:44,232 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:44,232 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:44,232 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:44,232 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:44,233 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:44,233 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:44,233 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:44,234 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:44,234 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:44,234 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:44,234 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:44,235 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:44,235 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:44,235 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:44,236 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:44,236 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:44,237 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:44,237 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:44,237 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:44,238 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:44,238 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:44,238 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:44,239 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:44,239 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:44,239 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:44,240 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:44,240 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:44,240 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:44,229 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:44,250 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:44,250 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:44,256 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:44,256 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:44,259 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:44,259 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:44,263 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:44,263 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:44,264 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:44,264 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:44,265 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-01-17T14:35:44,265 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-01-17T14:35:44,266 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:44,266 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:44,266 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:44,266 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:45,251 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:45,252 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21512
2022-01-17T14:35:45,252 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:45,252 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:45,252 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:45,252 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:45,253 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:45,253 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:45,255 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:35:45,256 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426545256
2022-01-17T14:35:45,256 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426545256
2022-01-17T14:35:45,258 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:45,530 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:45,530 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:45,530 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:45,531 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:45,531 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:45,531 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:45,531 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:45,532 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:45,532 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:45,532 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:45,533 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:45,533 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:45,533 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:45,534 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:45,534 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:45,534 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:45,535 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:45,535 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:45,535 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:45,536 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:45,536 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:45,536 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:45,536 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:45,537 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:45,537 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:45,537 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:45,538 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:45,538 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:45,538 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:45,539 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:45,539 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:45,539 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:45,540 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:45,540 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:45,541 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:45,541 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:45,541 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:45,542 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:45,542 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:45,542 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:45,543 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:45,543 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:45,543 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:45,543 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:45,531 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:45,546 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:45,546 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:45,547 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:45,547 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:45,550 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:45,550 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:45,552 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:45,552 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:45,552 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:45,552 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:45,553 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-17T14:35:45,553 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-17T14:35:45,555 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:45,555 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:45,555 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:45,555 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:51,554 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:51,554 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:35:52,177 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:52,177 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:35:52,272 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:52,272 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:35:53,560 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:53,560 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:35:54,283 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:54,284 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]992
2022-01-17T14:35:54,284 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:54,284 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:54,284 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:54,285 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:54,285 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:54,285 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:35:54,288 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:35:54,289 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426554289
2022-01-17T14:35:54,289 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426554289
2022-01-17T14:35:54,290 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:54,584 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:54,583 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:54,584 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:54,584 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:54,585 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:54,586 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:54,586 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:54,586 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:54,586 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:54,586 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:54,587 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:54,587 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:54,587 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:54,588 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:54,588 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:54,588 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:54,589 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:54,589 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:54,589 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:54,590 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:54,590 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:54,590 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:54,590 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:54,591 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:54,586 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:54,591 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:54,592 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:54,592 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:54,592 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:54,592 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:54,594 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:54,592 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:54,595 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:54,595 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:54,595 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:54,596 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:54,596 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:54,596 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:54,597 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:54,597 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:54,597 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:54,598 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:54,598 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:54,598 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:54,599 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:54,599 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:54,599 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:54,599 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:54,594 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:54,601 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:54,601 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:54,602 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:54,602 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:54,603 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:54,603 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:54,626 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-01-17T14:35:54,626 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-01-17T14:35:54,629 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:54,629 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:54,629 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:35:54,629 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:35:55,198 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:55,199 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22308
2022-01-17T14:35:55,199 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:55,199 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:55,200 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:55,200 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:55,201 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:55,201 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:35:55,204 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:35:55,204 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426555204
2022-01-17T14:35:55,204 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426555204
2022-01-17T14:35:55,206 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:55,353 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:55,354 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22488
2022-01-17T14:35:55,354 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:55,354 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:55,354 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:55,354 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:55,355 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:55,355 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:35:55,357 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426555356
2022-01-17T14:35:55,357 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426555356
2022-01-17T14:35:55,361 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:35:55,361 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:55,520 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:55,519 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:55,520 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:55,520 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:55,521 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:55,521 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:55,521 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:55,521 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:55,522 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:55,522 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:55,522 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:55,523 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:55,523 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:55,524 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:55,524 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:55,524 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:55,525 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:55,525 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:55,525 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:55,525 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:55,526 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:55,526 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:55,526 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:55,527 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:55,527 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:55,527 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:55,527 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:55,528 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:55,528 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:55,528 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:55,529 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:55,529 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:55,531 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:55,531 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:55,531 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:55,532 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:55,532 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:55,532 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:55,533 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:55,533 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:55,533 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:55,534 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:55,534 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:55,534 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:55,535 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:55,535 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:55,522 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:55,537 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:55,537 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:55,538 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:55,538 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:55,538 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:55,538 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:55,539 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:55,539 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:55,539 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-01-17T14:35:55,539 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-01-17T14:35:55,553 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:55,553 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:55,553 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:35:55,553 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:35:55,736 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:55,736 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:55,736 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:55,736 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:55,737 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:55,737 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:55,737 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:55,737 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:55,738 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:55,738 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:55,738 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:55,739 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:55,739 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:55,739 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:55,740 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:55,740 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:55,740 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:55,741 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:55,741 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:55,741 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:55,741 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:55,742 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:55,742 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:55,742 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:55,742 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:55,743 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:55,743 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:55,743 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:55,744 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:55,744 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:55,744 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:55,745 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:55,745 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:55,745 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:55,746 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:55,746 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:55,746 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:55,747 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:55,747 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:55,747 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:55,748 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:55,748 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:55,748 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:55,749 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:55,737 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:55,752 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:55,752 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:55,755 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:55,755 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:55,756 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:55,756 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:55,761 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:55,761 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:55,762 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:55,762 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:55,763 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-01-17T14:35:55,763 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-01-17T14:35:55,764 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:55,764 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:55,764 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:35:55,764 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:35:56,747 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:35:56,748 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]3720
2022-01-17T14:35:56,749 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:56,749 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:35:56,749 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:35:56,749 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:35:56,750 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:56,750 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:35:56,752 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:35:56,752 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426556752
2022-01-17T14:35:56,752 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426556752
2022-01-17T14:35:56,754 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:35:57,035 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:35:57,036 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:57,035 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:57,036 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:35:57,036 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:57,036 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:35:57,036 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:35:57,036 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:35:57,037 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:35:57,037 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:57,037 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:35:57,037 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:57,038 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:57,038 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:57,038 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:57,039 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:35:57,039 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:35:57,040 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:57,040 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:35:57,040 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:35:57,040 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:35:57,041 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:35:57,041 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:35:57,041 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:35:57,042 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:35:57,042 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:35:57,042 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:35:57,042 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:35:57,043 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:35:57,043 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:35:57,043 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:35:57,044 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:35:57,044 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:35:57,044 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:35:57,045 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:35:57,045 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:35:57,045 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:35:57,045 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:35:57,046 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:35:57,046 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:35:57,046 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:35:57,047 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:35:57,047 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:35:57,047 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:35:57,048 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:35:57,048 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:35:57,037 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:35:57,053 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:57,053 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:35:57,053 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:57,053 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:35:57,057 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:57,057 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:57,062 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:57,062 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:57,063 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-17T14:35:57,063 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-17T14:35:57,064 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:57,064 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:35:57,064 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:35:57,064 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:05,692 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:42:05,692 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:42:05,952 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: my_fancy_model=my_fancy_model.mar
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:42:05,952 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: my_fancy_model=my_fancy_model.mar
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:42:05,969 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:42:05,969 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:42:06,010 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: my_fancy_model.mar
2022-01-17T14:42:06,010 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: my_fancy_model.mar
2022-01-17T14:42:07,588 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_fancy_model
2022-01-17T14:42:07,588 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_fancy_model
2022-01-17T14:42:07,589 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_fancy_model
2022-01-17T14:42:07,589 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_fancy_model
2022-01-17T14:42:07,590 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_fancy_model loaded.
2022-01-17T14:42:07,590 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_fancy_model loaded.
2022-01-17T14:42:07,591 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_fancy_model, count: 4
2022-01-17T14:42:07,591 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_fancy_model, count: 4
2022-01-17T14:42:07,616 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:42:07,616 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:42:07,617 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:07,617 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:07,621 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:42:07,622 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:42:07,625 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:42:07,622 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:42:07,621 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:42:07,625 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:42:08,204 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:42:08,204 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:42:08,206 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:42:08,206 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:42:08,211 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:42:08,211 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:42:08,211 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:42:08,211 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:42:08,215 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:42:08,215 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:42:09,057 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-17T14:42:09,057 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-17T14:42:09,577 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426929
2022-01-17T14:42:09,584 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:75.43651962280273|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426929
2022-01-17T14:42:09,585 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:371.25|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426929
2022-01-17T14:42:09,586 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:83.1|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426929
2022-01-17T14:42:09,586 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:789.515625|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426929
2022-01-17T14:42:09,587 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7285.2421875|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426929
2022-01-17T14:42:09,588 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:90.2|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642426929
2022-01-17T14:42:11,641 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:11,650 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22644
2022-01-17T14:42:11,655 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:42:11,654 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:11,656 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:11,655 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:42:11,659 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:11,663 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22896
2022-01-17T14:42:11,663 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:11,664 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:42:11,664 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:11,664 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:42:11,664 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:42:11,664 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:42:11,674 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:42:11,674 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:42:11,687 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:42:11,688 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:42:11,694 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426931694
2022-01-17T14:42:11,695 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426931695
2022-01-17T14:42:11,694 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426931694
2022-01-17T14:42:11,695 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426931695
2022-01-17T14:42:11,703 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:11,705 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]12700
2022-01-17T14:42:11,706 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:42:11,706 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:11,706 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:11,706 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:42:11,708 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:42:11,708 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:42:11,710 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426931710
2022-01-17T14:42:11,710 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:42:11,710 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426931710
2022-01-17T14:42:11,751 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:11,751 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:11,751 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:11,902 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:11,904 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]18720
2022-01-17T14:42:11,904 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:11,904 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:42:11,904 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:42:11,906 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:42:11,906 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:42:11,906 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:11,909 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426931909
2022-01-17T14:42:11,909 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:42:11,909 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426931909
2022-01-17T14:42:11,950 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:12,189 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:12,190 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:12,191 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:12,191 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:12,192 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:12,192 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:12,192 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:12,193 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:12,194 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:12,194 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:12,195 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:12,196 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:12,196 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:12,197 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:12,197 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:12,198 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:12,199 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:12,199 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:12,200 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:12,200 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:12,201 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:12,202 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:12,202 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:12,203 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:12,203 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:12,204 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:12,204 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:12,205 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:12,206 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:12,207 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:12,207 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:12,208 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:12,208 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:12,209 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:12,209 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:42:12,210 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:42:12,210 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:42:12,211 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:42:12,212 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:42:12,212 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:42:12,213 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:42:12,214 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:42:12,214 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:42:12,216 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:12,216 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:12,221 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:12,221 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:12,243 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:12,243 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:12,244 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:12,244 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:12,245 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,245 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,245 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,245 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,247 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:42:12,247 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:42:12,254 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,254 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,254 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,254 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,281 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:12,282 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:12,283 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:12,283 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:12,283 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:12,284 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:12,285 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:12,285 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:12,286 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:12,286 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:12,287 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:12,287 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:12,287 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:12,288 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:12,288 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:12,289 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:12,289 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:12,290 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:12,290 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:12,291 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:12,291 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:12,292 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:12,292 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:12,292 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:12,293 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:12,293 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:12,294 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:12,294 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:12,295 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:12,287 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:12,296 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:12,297 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:12,297 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:12,297 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:12,298 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:12,299 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:12,299 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:12,300 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:42:12,300 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:42:12,300 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:42:12,301 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:42:12,301 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:42:12,302 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:42:12,297 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:12,303 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:42:12,304 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:42:12,305 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:42:12,304 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:12,304 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:12,305 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:12,305 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:12,306 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,306 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,307 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,307 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,307 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:42:12,307 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:42:12,324 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,324 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,324 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,324 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,333 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:12,334 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:12,334 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:12,334 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:12,334 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:12,335 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:12,336 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:12,336 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:12,336 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:12,336 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:12,337 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:12,337 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:12,337 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:12,338 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:12,342 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:12,343 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:12,343 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:12,337 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:12,343 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:12,344 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:12,344 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:12,344 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:12,344 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:12,345 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:12,345 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:12,345 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:12,345 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:12,346 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,346 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,346 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,346 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:12,346 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,346 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:12,349 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,349 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,354 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:42:12,357 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,354 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:42:12,357 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,436 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:12,435 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:12,436 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:12,436 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:12,438 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:12,438 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:12,438 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:12,439 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:12,439 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:12,440 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:12,440 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:12,441 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:12,441 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:12,438 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:12,442 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:12,442 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:12,442 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:12,443 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:12,442 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:12,444 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:12,444 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:12,445 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:12,444 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:12,445 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:12,445 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:12,446 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:12,446 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:12,447 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:12,447 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:12,448 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:12,448 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:12,449 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:12,449 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:12,450 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:12,450 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:12,451 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:12,452 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,452 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:12,452 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,453 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,453 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:12,453 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,453 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:12,454 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:42:12,454 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,454 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:42:12,454 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:12,459 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:12,459 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:13,252 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:13,252 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:13,315 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:42:13,315 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:42:13,364 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:42:13,364 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:42:13,459 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:42:13,459 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:42:16,604 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:16,605 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22972
2022-01-17T14:42:16,606 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:16,606 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:16,607 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:16,607 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:16,621 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:16,622 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21652
2022-01-17T14:42:16,622 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:16,622 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:16,623 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:42:16,623 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:42:16,622 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:16,625 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:16,622 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:42:16,626 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426936626
2022-01-17T14:42:16,622 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:42:16,627 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:42:16,638 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426936638
2022-01-17T14:42:16,626 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426936626
2022-01-17T14:42:16,637 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:42:16,638 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426936638
2022-01-17T14:42:16,684 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:16,690 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:16,831 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:16,832 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]14720
2022-01-17T14:42:16,833 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:16,834 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:16,834 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:16,834 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:16,835 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:42:16,835 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:42:16,837 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426936837
2022-01-17T14:42:16,837 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426936837
2022-01-17T14:42:16,837 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:42:16,850 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:17,010 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:17,011 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]20816
2022-01-17T14:42:17,011 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:17,012 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:17,012 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:17,013 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:42:17,013 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:42:17,015 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426937015
2022-01-17T14:42:17,015 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426937015
2022-01-17T14:42:17,017 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:17,020 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:42:17,041 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:17,349 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:17,348 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:17,349 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:17,350 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:17,358 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:17,357 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:17,365 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:17,367 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:17,367 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:17,367 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:17,368 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:17,368 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:17,369 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:17,369 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:17,369 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:17,370 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:17,370 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:17,371 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:17,371 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:17,371 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:17,371 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:17,372 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:17,372 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:17,373 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:17,373 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:17,373 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:17,374 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:17,374 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:17,374 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:17,375 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:17,376 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:17,376 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:17,377 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:17,377 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:17,377 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:17,378 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:17,378 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:42:17,378 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:42:17,379 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:42:17,379 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:42:17,379 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:42:17,380 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:42:17,381 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:42:17,358 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:17,374 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:17,393 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:17,394 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:17,373 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:17,394 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:42:17,394 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:17,409 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:17,393 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:17,411 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:17,438 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:17,409 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:42:17,411 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:17,409 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:17,438 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:17,438 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:17,455 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:17,455 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:17,455 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:17,455 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:17,456 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:17,456 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:17,456 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:17,457 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:17,457 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:17,457 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:17,458 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:17,458 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:17,459 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:17,458 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:17,455 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:17,455 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:17,464 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:17,459 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:17,464 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:17,409 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:17,468 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:17,464 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:17,466 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:17,466 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:17,469 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:17,458 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:17,468 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:17,469 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,469 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:17,469 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:17,469 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:17,470 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:17,498 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,498 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,469 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:17,469 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,498 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,513 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,498 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,515 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,469 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:17,519 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:17,470 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:17,471 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:17,526 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,531 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:17,515 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,562 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,513 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,562 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:42:17,531 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:17,563 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:17,530 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:17,526 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,521 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:17,562 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:42:17,520 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:17,519 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:17,607 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,599 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:17,598 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:17,613 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:17,614 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:17,614 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:17,615 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:17,563 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:17,562 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,627 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:17,628 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:42:17,627 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:17,630 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:17,635 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,630 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:17,615 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:17,656 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:17,607 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:17,607 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,656 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:17,677 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,677 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,676 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,677 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,681 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,655 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:17,685 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,635 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,631 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:17,628 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:42:17,685 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:17,681 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,695 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:42:17,676 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,677 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,697 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:42:17,682 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:17,702 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,697 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:42:17,695 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:42:17,687 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:17,702 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,703 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:17,703 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:18,567 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:18,567 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:18,630 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:42:18,630 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:42:18,710 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:42:18,710 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:42:18,710 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:42:18,710 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:42:22,111 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:22,112 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]23536
2022-01-17T14:42:22,113 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:22,113 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:22,113 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:22,113 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:22,148 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:42:22,148 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:42:22,154 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426942154
2022-01-17T14:42:22,154 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:42:22,154 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426942154
2022-01-17T14:42:22,157 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:22,159 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:22,160 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]9900
2022-01-17T14:42:22,161 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:22,161 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:22,161 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:22,161 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:22,170 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:42:22,170 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:42:22,201 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:42:22,204 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426942203
2022-01-17T14:42:22,204 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426942203
2022-01-17T14:42:22,209 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:22,395 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:22,396 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]20912
2022-01-17T14:42:22,397 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:22,397 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:22,397 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:22,397 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:22,401 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:42:22,401 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:42:22,409 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426942409
2022-01-17T14:42:22,409 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:42:22,409 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426942409
2022-01-17T14:42:22,411 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:22,539 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:22,540 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]20000
2022-01-17T14:42:22,541 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:22,540 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:22,541 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:22,541 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:22,543 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:42:22,543 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:42:22,551 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:42:22,552 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426942552
2022-01-17T14:42:22,552 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426942552
2022-01-17T14:42:22,553 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:22,737 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:22,738 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:22,738 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:22,738 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:22,738 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:22,739 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:22,739 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:22,739 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:22,739 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:22,740 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:22,741 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:22,741 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:22,741 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:22,742 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:22,744 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:22,744 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:22,745 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:22,745 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:22,746 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:22,746 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:22,746 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:22,747 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:22,747 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:22,747 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:22,747 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:22,748 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:22,748 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:22,748 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:22,749 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:22,749 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:22,750 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:22,750 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:22,750 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:22,752 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:22,752 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:22,752 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:22,753 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:22,753 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:22,754 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:22,754 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:42:22,754 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:42:22,755 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:42:22,755 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:42:22,755 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:42:22,756 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:42:22,744 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:22,757 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:22,757 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:42:22,757 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:22,757 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:42:22,758 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:42:22,758 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:22,758 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:22,759 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:22,759 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:22,759 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-17T14:42:22,759 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-17T14:42:22,770 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:22,770 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:22,770 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:22,770 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:22,841 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:22,840 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:22,841 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:22,841 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:22,842 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:22,842 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:22,842 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:22,842 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:22,843 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:22,843 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:22,843 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:22,844 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:22,844 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:22,844 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:22,845 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:22,845 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:22,845 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:22,846 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:22,846 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:22,846 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:22,847 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:22,847 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:22,847 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:22,847 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:22,848 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:22,848 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:22,848 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:22,849 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:22,850 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:22,851 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:22,851 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:22,852 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:22,852 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:22,853 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:22,853 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:22,853 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:42:22,854 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:42:22,854 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:42:22,854 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:42:22,855 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:42:22,856 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:42:22,842 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:22,856 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:42:22,857 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:42:22,857 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:42:22,857 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:22,857 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:22,865 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:22,865 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:22,867 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:22,867 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:22,869 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:22,869 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:22,870 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:22,870 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:22,871 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-01-17T14:42:22,871 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-01-17T14:42:22,874 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:22,874 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:22,874 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:22,874 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:23,017 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:23,016 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:23,017 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:23,017 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:23,018 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:23,018 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:23,018 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:23,019 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:23,019 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:23,019 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:23,020 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:23,020 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:23,020 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:23,021 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:23,021 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:23,021 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:23,021 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:23,022 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:23,022 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:23,022 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:23,023 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:23,023 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:23,023 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:23,024 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:23,024 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:23,024 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:23,024 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:23,025 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:23,026 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:23,026 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:23,027 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:23,027 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:23,027 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:23,028 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:23,028 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:42:23,028 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:23,028 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:42:23,028 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:23,028 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:42:23,035 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:42:23,035 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:42:23,036 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:42:23,035 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:23,037 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:42:23,037 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:42:23,037 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:42:23,035 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:23,040 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:23,040 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:23,051 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:23,051 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:23,052 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:23,052 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:23,054 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:23,054 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:23,057 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-01-17T14:42:23,057 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-01-17T14:42:23,059 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:23,059 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:23,059 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:23,059 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:23,091 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:23,091 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:23,091 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:23,092 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:23,092 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:23,093 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:23,093 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:23,093 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:23,093 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:23,094 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:23,094 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:23,095 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:23,095 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:23,095 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:23,096 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:23,096 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:23,096 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:23,097 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:23,097 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:23,097 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:23,097 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:23,098 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:23,098 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:23,098 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:23,099 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:23,099 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:23,099 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:23,100 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:23,101 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:23,102 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:23,103 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:23,103 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:23,104 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:23,104 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:23,104 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:23,105 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:42:23,105 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:42:23,105 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:42:23,106 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:42:23,106 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:42:23,106 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:42:23,107 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:42:23,108 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:42:23,108 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:42:23,093 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:23,109 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:23,109 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:23,112 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:23,112 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:23,113 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:23,113 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:23,114 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:23,114 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:23,114 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:23,114 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:23,114 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-17T14:42:23,114 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-17T14:42:23,121 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:23,121 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:23,121 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:23,121 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:24,765 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:24,765 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:24,877 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:42:24,877 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:42:25,068 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:42:25,068 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:42:25,121 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:42:25,121 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:42:28,758 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:28,763 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]10200
2022-01-17T14:42:28,765 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:28,766 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:28,767 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:28,767 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:28,768 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:42:28,768 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:42:28,771 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426948771
2022-01-17T14:42:28,771 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:42:28,771 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426948771
2022-01-17T14:42:28,772 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:28,833 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:28,836 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21300
2022-01-17T14:42:28,836 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:28,837 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:28,837 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:28,837 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:28,838 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:42:28,838 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:42:28,839 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426948839
2022-01-17T14:42:28,839 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426948839
2022-01-17T14:42:28,845 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:42:28,847 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:29,039 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:29,041 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]18116
2022-01-17T14:42:29,042 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:29,042 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:29,042 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:29,042 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:29,044 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:42:29,044 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:42:29,050 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:42:29,052 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426949052
2022-01-17T14:42:29,052 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426949052
2022-01-17T14:42:29,053 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:29,178 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:29,177 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:29,178 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:29,178 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:29,178 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:29,178 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:29,178 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:29,179 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:29,179 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:29,179 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:29,180 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:29,180 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:29,180 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:29,181 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:29,181 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:29,181 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:29,182 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:29,182 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:29,182 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:29,182 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:29,183 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:29,183 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:29,183 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:29,184 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:29,184 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:29,184 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:29,185 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:29,185 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:29,185 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:29,186 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:29,187 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:29,187 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:29,188 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:29,188 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:29,188 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:29,189 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:42:29,189 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:42:29,189 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:42:29,190 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:42:29,190 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:42:29,191 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:42:29,191 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:42:29,192 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:42:29,192 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:42:29,178 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:29,199 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:29,199 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:29,207 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:29,207 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:29,210 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:29,210 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:29,212 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,212 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,220 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,222 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,220 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,222 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,222 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-17T14:42:29,222 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,222 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,222 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-17T14:42:29,276 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:29,274 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:29,276 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:29,276 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:29,278 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:29,279 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:29,279 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:29,279 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:29,279 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:29,280 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:29,280 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:29,281 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:29,281 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:29,280 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:29,281 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:29,282 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:29,282 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:29,282 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:29,282 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:29,283 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:29,283 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:29,283 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:29,284 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:29,284 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:29,285 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:29,285 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:29,286 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:42:29,286 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:42:29,286 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:42:29,287 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:42:29,287 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:42:29,288 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:42:29,289 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:42:29,289 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:29,289 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:29,290 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:29,290 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:29,290 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:42:29,291 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:42:29,291 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:42:29,291 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:42:29,292 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:42:29,292 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:42:29,293 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:42:29,293 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:42:29,293 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:42:29,280 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:29,297 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:29,297 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:29,298 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:29,298 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:29,298 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,298 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,299 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,299 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,299 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-01-17T14:42:29,299 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-01-17T14:42:29,303 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:42:29,304 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]7352
2022-01-17T14:42:29,306 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:29,306 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:42:29,306 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:42:29,307 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:42:29,308 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:42:29,308 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:42:29,309 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,309 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,309 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,309 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,312 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426949312
2022-01-17T14:42:29,312 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:42:29,312 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642426949312
2022-01-17T14:42:29,314 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:42:29,469 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:29,469 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:29,469 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:29,469 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:29,470 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:29,470 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:29,470 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:29,471 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:29,471 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:29,471 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:29,471 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:29,472 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:29,472 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:29,470 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:29,481 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:29,481 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:29,479 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:29,484 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:29,486 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:29,485 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:29,486 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:29,486 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:29,486 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:29,488 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,488 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,489 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,487 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:29,489 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:29,492 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:29,489 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,493 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-01-17T14:42:29,492 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:29,493 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,493 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-01-17T14:42:29,493 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,495 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,495 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,604 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:42:29,605 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:29,605 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:29,605 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:42:29,605 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:42:29,606 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:29,605 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:42:29,606 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:42:29,606 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:42:29,606 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:42:29,607 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:42:29,607 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:42:29,606 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:42:29,609 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:29,609 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:42:29,612 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:29,607 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:42:29,612 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:42:29,618 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:29,618 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:42:29,620 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,615 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:42:29,620 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,622 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,621 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:42:29,623 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:29,623 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:42:29,624 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:42:29,624 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:42:29,624 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:42:29,625 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:42:29,625 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:42:29,625 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:42:29,622 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,627 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-01-17T14:42:29,627 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-01-17T14:42:29,626 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:42:29,627 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,627 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:42:29,631 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:29,631 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:42:32,240 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:32,240 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:42:32,248 [INFO ] nioEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-17T14:42:32,248 [INFO ] nioEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-17T14:50:07,613 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:50:07,613 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:50:07,861 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: my_fancy_model=my_fancy_model.mar
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:50:07,861 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: my_fancy_model=my_fancy_model.mar
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:50:07,877 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:50:07,877 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:50:07,916 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: my_fancy_model.mar
2022-01-17T14:50:07,916 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: my_fancy_model.mar
2022-01-17T14:50:09,460 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_fancy_model
2022-01-17T14:50:09,460 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_fancy_model
2022-01-17T14:50:09,461 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_fancy_model
2022-01-17T14:50:09,461 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_fancy_model
2022-01-17T14:50:09,462 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_fancy_model loaded.
2022-01-17T14:50:09,462 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_fancy_model loaded.
2022-01-17T14:50:09,462 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_fancy_model, count: 4
2022-01-17T14:50:09,462 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_fancy_model, count: 4
2022-01-17T14:50:09,481 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:09,481 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:09,481 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:09,481 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:09,481 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:09,481 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:09,493 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:09,486 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:50:09,486 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:50:09,493 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:10,102 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:50:10,102 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:50:10,103 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:50:10,103 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:50:10,105 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:50:10,105 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:50:10,106 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:50:10,106 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:50:10,107 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:50:10,107 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:50:11,026 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-17T14:50:11,026 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-17T14:50:11,561 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427411
2022-01-17T14:50:11,586 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:75.1822395324707|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427411
2022-01-17T14:50:11,587 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:371.50428009033203|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427411
2022-01-17T14:50:11,588 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:83.2|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427411
2022-01-17T14:50:11,588 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1005.33203125|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427411
2022-01-17T14:50:11,589 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7069.42578125|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427411
2022-01-17T14:50:11,590 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:87.5|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427411
2022-01-17T14:50:13,447 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:13,448 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:13,453 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21832
2022-01-17T14:50:13,453 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]23500
2022-01-17T14:50:13,453 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:13,453 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:13,453 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:13,454 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:13,455 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:50:13,455 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:50:13,455 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:50:13,455 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:50:13,461 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:13,461 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:13,461 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:13,461 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:13,480 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:50:13,480 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:50:13,486 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427413485
2022-01-17T14:50:13,486 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427413485
2022-01-17T14:50:13,486 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427413485
2022-01-17T14:50:13,486 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427413485
2022-01-17T14:50:13,541 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:13,541 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:13,620 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:13,623 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]19840
2022-01-17T14:50:13,625 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:13,626 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:50:13,626 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:50:13,627 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:13,630 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:13,630 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:13,634 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427413634
2022-01-17T14:50:13,634 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:50:13,634 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427413634
2022-01-17T14:50:13,661 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:13,750 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:13,751 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22676
2022-01-17T14:50:13,751 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:50:13,751 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:13,751 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:50:13,752 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:13,752 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:13,752 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:13,755 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:50:13,756 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427413756
2022-01-17T14:50:13,756 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427413756
2022-01-17T14:50:13,797 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:14,013 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:14,013 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:14,013 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:14,013 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:14,010 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:14,010 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:14,043 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:14,044 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:14,045 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:14,045 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:14,046 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:14,046 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:14,049 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:14,046 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:14,043 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:14,046 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:14,049 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:14,067 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:14,068 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:14,068 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:14,068 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:14,068 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:14,081 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:14,068 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:14,068 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:14,099 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:14,069 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:14,081 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:14,100 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:14,100 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:14,099 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:14,114 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:14,101 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:14,100 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:14,100 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:14,115 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:14,114 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:14,115 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:14,115 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:14,137 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,137 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,137 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:14,137 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,138 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,115 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:14,137 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,138 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:14,139 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:14,149 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,138 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,149 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:14,151 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,151 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,150 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:14,151 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:50:14,151 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:50:14,155 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,158 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:14,149 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,152 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:14,158 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:14,162 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,157 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:14,155 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,162 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:14,162 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:14,162 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,163 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:50:14,183 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,162 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:14,162 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:14,183 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,185 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:14,186 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:14,186 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:14,187 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:14,188 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:14,163 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:50:14,190 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:14,191 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:14,184 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:14,192 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:14,184 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:14,192 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:14,199 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:14,199 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:14,200 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:14,199 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:14,201 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:14,201 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:14,201 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:14,201 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:14,202 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:14,228 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:14,228 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,228 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:14,229 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:14,229 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:14,234 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:14,234 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:14,235 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:14,235 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:14,235 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:14,228 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,237 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,238 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,237 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:14,238 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,247 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:14,248 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:14,237 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,248 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:14,249 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,249 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,250 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:50:14,250 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:50:14,394 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:14,393 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:14,394 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:14,394 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:14,395 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:14,395 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:14,395 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:14,396 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:14,396 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:14,397 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:14,397 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:14,398 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:14,398 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:14,399 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:14,399 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:14,399 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:14,400 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:14,401 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:14,401 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:14,401 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:14,402 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:14,402 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:14,403 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:14,403 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:14,404 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:14,404 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:14,405 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:14,405 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:14,406 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:14,407 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:14,408 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:14,395 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:14,409 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:14,409 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:14,409 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:14,410 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:14,410 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:14,414 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:14,415 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:14,415 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:14,409 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:14,416 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:14,416 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:14,417 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:14,417 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:14,417 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:14,418 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:14,418 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:14,418 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:14,419 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:14,419 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:14,421 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,421 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,422 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,422 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,423 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:50:14,423 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:50:14,425 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,425 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:14,425 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:14,425 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:15,163 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:15,163 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:15,185 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:15,185 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:15,263 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:15,263 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:15,431 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:15,431 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:18,345 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:18,347 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21740
2022-01-17T14:50:18,348 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:18,348 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:18,348 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:18,348 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:18,352 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:18,352 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:18,355 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:50:18,355 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427418355
2022-01-17T14:50:18,355 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427418355
2022-01-17T14:50:18,380 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:18,405 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:18,410 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21592
2022-01-17T14:50:18,412 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:18,416 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:18,416 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:18,417 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:18,417 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:18,419 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:18,434 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:50:18,435 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427418435
2022-01-17T14:50:18,435 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427418435
2022-01-17T14:50:18,451 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:18,539 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:18,540 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]1040
2022-01-17T14:50:18,541 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:18,541 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:18,541 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:18,541 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:18,543 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:18,543 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:18,547 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:50:18,547 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427418547
2022-01-17T14:50:18,547 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427418547
2022-01-17T14:50:18,558 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:18,803 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:18,804 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:18,804 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:18,805 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:18,805 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:18,806 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:18,806 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:18,807 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:18,807 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:18,808 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:18,808 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:18,809 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:18,809 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:18,809 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:18,810 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:18,810 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:18,811 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:18,811 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:18,811 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:18,812 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:18,812 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:18,812 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:18,813 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:18,813 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:18,813 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:18,814 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:18,813 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:18,814 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:18,814 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:18,815 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:18,816 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:18,816 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:18,816 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:18,816 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:18,817 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:18,817 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:18,817 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:18,818 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:18,818 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:18,818 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:18,818 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:18,819 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:18,819 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:18,819 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:18,820 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:18,820 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:18,820 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:18,820 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:18,820 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:18,821 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:18,821 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:18,821 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:18,822 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:18,822 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:18,822 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:18,822 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:18,823 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:18,823 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:18,823 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:18,823 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:18,824 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:18,825 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:18,825 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:18,825 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:18,825 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:18,826 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:18,826 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:18,826 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:18,827 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:18,828 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:18,829 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:18,829 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:18,829 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:18,830 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:18,830 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:18,831 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:18,831 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:18,832 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:18,832 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:18,832 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:18,833 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:18,834 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:18,834 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:18,835 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:18,836 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:18,836 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:18,838 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:18,838 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:18,840 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:18,840 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:18,840 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:18,840 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:18,855 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:18,855 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:18,855 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:18,875 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:18,855 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:18,890 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:18,875 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:18,890 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:18,891 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:18,892 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:18,891 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:18,903 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:50:18,911 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:18,911 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:18,903 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-01-17T14:50:18,892 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:18,911 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:18,914 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:18,911 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:18,914 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:18,915 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:18,915 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:18,916 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:18,916 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:18,916 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:50:18,916 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-01-17T14:50:18,925 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:18,925 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:18,925 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:18,925 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:18,982 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:18,982 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:18,982 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:18,983 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:18,983 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:18,983 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:18,984 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:18,984 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:18,984 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:18,985 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:18,985 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:18,986 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:18,986 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:18,986 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:18,987 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:18,987 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:18,988 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:18,988 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:18,988 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:18,989 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:18,989 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:18,989 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:18,990 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:18,990 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:18,991 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:18,991 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:18,992 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:18,992 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:18,992 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:18,994 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:18,994 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:18,995 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:18,995 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:18,996 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:18,996 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:18,997 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:18,997 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:18,997 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:18,998 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:18,998 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:18,999 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:18,983 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:19,001 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:19,002 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:19,002 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:19,002 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:19,002 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:19,009 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:19,009 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:19,010 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:19,010 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:19,012 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:19,012 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:19,013 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:19,013 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:19,013 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:50:19,013 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-17T14:50:19,022 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:19,022 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:19,022 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:19,022 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:19,118 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:19,119 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]8500
2022-01-17T14:50:19,120 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:19,120 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:19,120 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:19,120 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:19,121 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:19,121 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:19,123 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427419123
2022-01-17T14:50:19,123 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427419123
2022-01-17T14:50:19,123 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:50:19,162 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:19,414 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:19,414 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:19,414 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:19,414 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:19,416 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:19,415 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:19,416 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:19,417 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:19,417 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:19,417 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:19,418 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:19,416 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:19,418 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:19,419 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:19,419 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:19,419 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:19,420 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:19,420 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:19,420 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:19,419 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:19,421 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:19,421 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:19,421 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:19,421 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:19,422 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:19,422 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:19,423 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:19,423 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:19,423 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:19,423 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:19,424 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:19,425 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:19,426 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:19,426 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:19,427 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:19,427 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:19,427 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:19,428 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:19,428 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:19,429 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:19,429 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:19,429 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:19,430 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:19,419 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:19,431 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:19,433 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:19,434 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:19,434 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:19,434 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:19,435 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:19,435 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:19,436 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:19,436 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:19,436 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:19,436 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:19,437 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:50:19,437 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-17T14:50:19,444 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:19,444 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:19,444 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:19,444 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:19,912 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:19,912 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:19,928 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:19,928 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:20,022 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:20,022 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:20,451 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:20,451 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:22,946 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:22,947 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]13144
2022-01-17T14:50:22,948 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:22,948 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:22,948 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:22,950 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:22,957 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:22,957 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:22,962 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:22,967 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]15548
2022-01-17T14:50:22,968 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:22,968 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:22,968 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:22,968 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:22,969 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:22,969 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:22,971 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427422971
2022-01-17T14:50:22,971 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427422971
2022-01-17T14:50:22,971 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:50:22,972 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:22,973 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:50:22,974 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427422974
2022-01-17T14:50:22,974 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427422974
2022-01-17T14:50:22,977 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:22,979 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:22,981 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]11732
2022-01-17T14:50:22,982 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:22,982 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:22,982 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:22,983 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:22,983 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:22,985 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427422985
2022-01-17T14:50:22,985 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427422985
2022-01-17T14:50:22,986 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:22,987 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:50:22,989 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:23,307 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:23,307 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:23,307 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:23,307 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:23,307 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:23,311 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:23,307 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:23,311 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:23,308 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:23,312 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:23,312 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:23,312 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:23,313 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:23,313 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:23,313 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:23,314 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:23,314 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:23,315 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:23,315 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:23,315 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:23,316 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:23,316 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:23,316 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:23,317 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:23,317 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:23,317 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:23,318 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:23,318 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:23,319 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:23,319 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:23,319 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:23,320 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:23,320 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:23,321 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:23,322 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:23,322 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:23,323 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:23,323 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:23,323 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:23,324 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:23,325 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:23,325 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:23,325 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:23,326 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:23,326 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:23,327 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:23,328 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:23,328 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:23,311 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:23,339 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:23,340 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:23,340 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:23,341 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:23,341 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:23,342 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:23,342 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:23,342 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:23,343 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:23,343 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:23,344 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:23,344 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:23,344 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:23,345 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:23,345 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:23,345 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:23,346 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:23,346 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:23,346 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:23,346 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:23,347 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:23,347 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:23,347 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:23,348 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:23,349 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:23,350 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:23,350 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:23,350 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:23,351 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:23,353 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:23,354 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:23,355 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:23,355 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:23,356 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:23,356 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:23,357 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:23,358 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:23,359 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:23,359 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:23,311 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:23,311 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:23,372 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:23,372 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:23,372 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:23,375 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:23,372 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:23,376 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:23,375 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:23,376 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:23,390 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:23,390 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:23,391 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,390 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:23,391 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,392 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,392 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,392 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-01-17T14:50:23,390 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:23,392 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-01-17T14:50:23,398 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,402 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,402 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,398 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,407 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,402 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,402 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,407 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,409 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-17T14:50:23,415 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,415 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,409 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-17T14:50:23,415 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,415 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,470 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:23,471 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:23,470 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:23,471 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:23,472 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:23,473 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:23,473 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:23,474 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:23,474 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:23,475 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:23,476 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:23,476 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:23,477 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:23,477 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:23,477 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:23,477 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:23,478 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:23,478 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:23,478 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:23,479 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:23,479 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:23,479 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:23,480 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:23,480 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:23,480 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:23,481 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:23,481 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:23,481 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:23,482 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:23,473 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:23,483 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:23,490 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:23,490 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:23,489 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:23,490 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:23,491 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:23,491 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:23,492 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:23,492 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:23,492 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:23,493 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:23,493 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:23,494 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:23,494 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:23,495 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:23,495 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:23,489 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:23,502 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:23,502 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:23,503 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:23,503 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:23,509 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,509 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,510 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,510 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,511 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-01-17T14:50:23,511 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-01-17T14:50:23,513 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,514 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,513 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:23,514 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:23,884 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:23,885 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]17812
2022-01-17T14:50:23,886 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:23,886 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:23,886 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:23,886 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:23,887 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:23,887 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:23,889 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427423889
2022-01-17T14:50:23,889 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:50:23,889 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427423889
2022-01-17T14:50:23,890 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:24,151 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:24,152 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:24,152 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:24,152 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:24,153 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:24,153 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:24,153 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:24,153 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:24,154 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:24,154 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:24,154 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:24,155 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:24,155 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:24,155 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:24,156 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:24,156 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:24,156 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:24,157 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:24,157 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:24,157 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:24,158 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:24,158 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:24,153 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:24,158 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:24,159 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:24,159 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:24,159 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:24,159 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:24,159 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:24,160 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:24,160 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:24,159 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:24,162 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:24,161 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:24,162 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:24,162 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:24,163 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:24,163 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:24,163 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:24,164 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:24,164 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:24,165 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:24,165 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:24,165 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:24,165 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:24,165 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:24,166 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-17T14:50:24,165 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:24,166 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:24,166 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-17T14:50:24,166 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:24,171 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:24,171 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:25,397 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:25,397 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:25,416 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:25,416 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:25,524 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:25,524 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:26,175 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:26,175 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:28,390 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:28,393 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]5824
2022-01-17T14:50:28,394 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:28,394 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:28,394 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:28,395 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:28,395 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:28,395 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:28,397 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427428397
2022-01-17T14:50:28,397 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:50:28,397 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427428397
2022-01-17T14:50:28,399 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:28,537 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:28,538 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]6100
2022-01-17T14:50:28,539 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:28,539 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:28,539 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:28,539 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:28,541 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:28,539 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:28,566 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:50:28,568 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427428568
2022-01-17T14:50:28,568 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427428568
2022-01-17T14:50:28,572 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:28,654 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:28,657 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]23400
2022-01-17T14:50:28,657 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:28,658 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:28,658 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:28,658 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:28,661 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:28,661 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:28,665 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:50:28,666 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427428666
2022-01-17T14:50:28,666 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427428666
2022-01-17T14:50:28,667 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:28,899 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:28,900 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:28,900 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:28,901 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:28,901 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:28,902 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:28,902 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:28,902 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:28,902 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:28,903 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:28,903 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:28,903 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:28,904 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:28,904 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:28,904 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:28,905 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:28,905 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:28,905 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:28,906 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:28,906 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:28,906 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:28,906 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:28,907 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:28,907 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:28,908 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:28,908 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:28,909 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:28,910 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:28,910 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:28,911 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:28,911 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:28,911 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:28,912 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:28,912 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:28,912 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:28,913 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:28,913 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:28,913 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:28,914 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:28,915 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:28,915 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:28,929 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:28,929 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:28,930 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:28,930 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:28,941 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:28,941 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:28,948 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:28,948 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:28,951 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:28,951 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:28,953 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:28,953 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:28,959 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:28,959 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:28,961 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-01-17T14:50:28,961 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-01-17T14:50:28,963 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:28,963 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:28,963 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:28,963 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:28,966 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:28,966 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:28,966 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:28,966 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:28,966 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:28,966 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:28,966 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:28,967 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:28,967 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:28,967 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:28,967 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:28,968 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:28,969 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:28,969 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:28,970 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:28,970 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:28,969 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:28,970 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:28,971 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:28,971 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:28,971 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:28,971 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:28,972 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:28,972 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:28,972 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:28,978 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:28,972 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:28,978 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:28,979 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:28,979 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:28,979 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:28,979 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:28,980 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:28,980 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:28,980 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:28,981 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:28,981 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:28,981 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:28,982 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:28,983 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:28,983 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:28,984 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:28,984 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:28,984 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:28,984 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:28,985 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:28,985 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:28,986 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:28,986 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:28,986 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:28,987 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:28,987 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:28,988 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:28,988 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:28,994 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:28,994 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:28,978 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:28,995 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-01-17T14:50:28,994 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:28,994 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:28,995 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-01-17T14:50:29,124 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:29,125 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:29,125 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:29,125 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:29,125 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:29,126 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:29,126 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:29,126 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:29,126 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:29,126 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:29,127 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:29,127 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:29,127 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:29,128 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:29,128 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:29,128 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:29,129 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:29,129 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:29,129 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:29,130 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:29,130 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:29,130 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:29,131 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:29,131 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:29,131 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:29,131 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:29,132 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:29,132 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:29,132 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:29,126 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:29,134 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:29,134 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:29,134 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:29,134 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:29,135 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:29,134 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:29,135 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:29,137 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:29,137 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:29,137 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:29,137 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:29,138 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:29,137 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:29,138 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:29,138 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:29,138 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:29,138 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:29,139 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:29,138 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:29,139 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:29,139 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-01-17T14:50:29,139 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:29,140 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:29,139 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-01-17T14:50:29,140 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:29,144 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:29,144 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:29,870 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:29,871 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21028
2022-01-17T14:50:29,871 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:29,871 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:29,871 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:29,871 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:29,872 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:29,872 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:29,874 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427429874
2022-01-17T14:50:29,874 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427429874
2022-01-17T14:50:29,874 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:50:29,876 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:30,193 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:30,194 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:30,194 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:30,194 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:30,194 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:30,195 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:30,195 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:30,195 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:30,196 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:30,196 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:30,196 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:30,197 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:30,197 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:30,197 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:30,198 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:30,198 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:30,198 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:30,199 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:30,199 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:30,199 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:30,199 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:30,200 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:30,200 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:30,200 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:30,201 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:30,201 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:30,201 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:30,201 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:30,202 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:30,195 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:30,203 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:30,207 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:30,207 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:30,208 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:30,208 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:30,208 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:30,209 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:30,209 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:30,210 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:30,211 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:30,211 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:30,211 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:30,206 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:30,213 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:30,213 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:30,213 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:30,206 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:30,216 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:30,216 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:30,217 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:30,217 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:30,218 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:30,218 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:30,218 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:30,218 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:30,219 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-17T14:50:30,219 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-17T14:50:30,232 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:30,232 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:30,232 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:30,232 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:31,971 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:31,971 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:32,003 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:32,003 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:32,146 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:32,146 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:33,228 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:33,228 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:34,932 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:34,935 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]20584
2022-01-17T14:50:34,935 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:34,935 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:34,939 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:34,935 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:34,947 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:34,947 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:34,952 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427434952
2022-01-17T14:50:34,951 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:50:34,952 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427434952
2022-01-17T14:50:34,958 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:34,973 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:34,974 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]12700
2022-01-17T14:50:34,975 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:34,975 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:34,975 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:34,985 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:34,976 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:34,985 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:34,990 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427434990
2022-01-17T14:50:34,990 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427434990
2022-01-17T14:50:34,990 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:50:34,991 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:35,310 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:35,312 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]12432
2022-01-17T14:50:35,312 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:35,312 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:35,312 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:35,312 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:35,314 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:35,314 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:35,316 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:50:35,316 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427435316
2022-01-17T14:50:35,316 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427435316
2022-01-17T14:50:35,318 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:35,467 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:35,466 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:35,467 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:35,467 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:35,467 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:35,467 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:35,467 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:35,468 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:35,468 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:35,469 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:35,469 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:35,469 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:35,470 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:35,470 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:35,470 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:35,471 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:35,471 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:35,471 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:35,472 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:35,472 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:35,472 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:35,472 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:35,473 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:35,473 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:35,473 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:35,473 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:35,474 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:35,474 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:35,474 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:35,475 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:35,475 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:35,476 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:35,477 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:35,477 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:35,477 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:35,478 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:35,478 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:35,478 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:35,479 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:35,479 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:35,479 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:35,480 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:35,480 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:35,480 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:35,481 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:35,481 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:35,485 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:35,485 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:35,485 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:35,498 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:35,498 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:35,498 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:35,499 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:35,499 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:35,500 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:35,500 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:35,500 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:35,501 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:35,501 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:35,501 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:35,501 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:35,502 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:35,502 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:35,502 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:35,503 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:35,503 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:35,503 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:35,503 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:35,504 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:35,504 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:35,504 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:35,504 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:35,505 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:35,505 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:35,505 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:35,506 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:35,506 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:35,506 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:35,507 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:35,507 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:35,507 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:35,508 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:35,509 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:35,511 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:35,512 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:35,498 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:35,513 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:35,513 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:35,513 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:35,468 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:35,515 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:35,513 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:35,515 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:35,517 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:35,514 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:35,518 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:35,518 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:35,517 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:35,519 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,519 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,519 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,519 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:35,519 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,519 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-01-17T14:50:35,519 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:35,519 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-01-17T14:50:35,521 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:35,521 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:35,523 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,525 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,525 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,523 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,530 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,525 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,525 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,536 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,536 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,530 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,537 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-01-17T14:50:35,536 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,536 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,537 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-01-17T14:50:35,694 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:35,694 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:35,694 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:35,694 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:35,694 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:35,695 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:35,695 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:35,695 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:35,695 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:35,696 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:35,696 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:35,696 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:35,696 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:35,697 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:35,697 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:35,697 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:35,698 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:35,698 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:35,698 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:35,699 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:35,699 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:35,699 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:35,700 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:35,700 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:35,700 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:35,700 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:35,701 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:35,701 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:35,701 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:35,702 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:35,702 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:35,702 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:35,703 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:35,703 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:35,703 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:35,703 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:35,704 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:35,704 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:35,704 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:35,705 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:35,705 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:35,705 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:35,706 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:35,706 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:35,706 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:35,707 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:35,696 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:35,710 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:35,710 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:35,712 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:35,712 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:35,713 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,713 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,714 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,714 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,716 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-01-17T14:50:35,716 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-01-17T14:50:35,719 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,719 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:35,719 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:35,719 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:36,585 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:36,586 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]8296
2022-01-17T14:50:36,586 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:36,587 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:36,587 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:36,587 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:36,587 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:36,587 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:36,589 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427436589
2022-01-17T14:50:36,589 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:50:36,589 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427436589
2022-01-17T14:50:36,591 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:36,881 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:36,881 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:36,881 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:36,881 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:36,882 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:36,882 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:36,882 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:36,883 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:36,883 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:36,883 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:36,884 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:36,884 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:36,884 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:36,885 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:36,885 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:36,885 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:36,885 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:36,886 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:36,886 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:36,886 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:36,886 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:36,887 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:36,887 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:36,887 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:36,888 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:36,888 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:36,888 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:36,888 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:36,889 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:36,889 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:36,890 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:36,890 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:36,890 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:36,891 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:36,891 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:36,891 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:36,892 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:36,892 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:36,892 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:36,893 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:36,893 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:36,893 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:36,894 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:36,894 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:36,882 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:36,896 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:36,896 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:36,899 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:36,899 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:36,900 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:36,900 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:36,901 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:36,901 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:36,902 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:36,902 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:36,903 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-17T14:50:36,903 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-17T14:50:36,906 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:36,906 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:36,906 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:36,906 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:40,532 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:40,532 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:40,547 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:40,547 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:40,721 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:40,721 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:41,909 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:41,909 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:43,466 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:43,467 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]12692
2022-01-17T14:50:43,468 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:43,468 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:43,469 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:43,468 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:43,469 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:43,469 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:43,471 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427443471
2022-01-17T14:50:43,471 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427443471
2022-01-17T14:50:43,474 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:50:43,475 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:43,551 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:43,552 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22608
2022-01-17T14:50:43,552 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:43,552 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:43,552 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:43,554 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:43,553 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:43,554 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:43,556 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427443556
2022-01-17T14:50:43,556 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427443556
2022-01-17T14:50:43,556 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:50:43,557 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:43,693 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:43,693 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21684
2022-01-17T14:50:43,694 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:43,694 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:43,695 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:43,695 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:43,695 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:43,695 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:43,697 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:50:43,698 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427443698
2022-01-17T14:50:43,698 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427443698
2022-01-17T14:50:43,699 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:43,878 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:43,877 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:43,878 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:43,878 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:43,881 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:43,882 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:43,882 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:43,883 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:43,883 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:43,883 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:43,884 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:43,884 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:43,884 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:43,884 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:43,885 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:43,885 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:43,885 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:43,885 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:43,886 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:43,886 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:43,886 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:43,887 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:43,887 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:43,887 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:43,887 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:43,888 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:43,888 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:43,888 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:43,889 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:43,889 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:43,889 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:43,890 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:43,890 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:43,890 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:43,891 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:43,891 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:43,891 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:43,892 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:43,892 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:43,892 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:43,893 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:43,893 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:43,894 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:43,894 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:43,898 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:43,898 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:43,899 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:43,899 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:43,899 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:43,899 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:43,900 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:43,900 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:43,900 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:43,900 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:43,901 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:43,901 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:43,901 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:43,902 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:43,902 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:43,902 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:43,902 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:43,903 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:43,903 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:43,903 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:43,903 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:43,904 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:43,904 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:43,904 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:43,905 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:43,905 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:43,905 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:43,905 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:43,906 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:43,906 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:43,906 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:43,907 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:43,907 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:43,907 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:43,908 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:43,908 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:43,908 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:43,909 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:43,909 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:43,909 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:43,910 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:43,910 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:43,884 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:43,899 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:43,917 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:43,922 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:43,917 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:43,923 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:43,923 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:43,926 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:43,926 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:43,929 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:43,922 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:43,929 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:43,933 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:43,932 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:43,933 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:43,937 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:43,937 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:43,938 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-01-17T14:50:43,939 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:43,938 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-01-17T14:50:43,932 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:43,939 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:43,957 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:43,957 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:43,957 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:43,957 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:43,958 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:43,958 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:43,990 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:44,002 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:44,002 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:43,990 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:44,007 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-01-17T14:50:44,002 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:44,002 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:44,007 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-01-17T14:50:44,164 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:44,164 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:44,164 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:44,164 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:44,165 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:44,165 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:44,166 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:44,166 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:44,166 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:44,166 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:44,167 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:44,167 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:44,167 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:44,168 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:44,168 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:44,168 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:44,168 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:44,169 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:44,169 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:44,169 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:44,170 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:44,170 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:44,170 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:44,170 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:44,171 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:44,171 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:44,171 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:44,172 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:44,172 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:44,172 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:44,173 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:44,173 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:44,173 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:44,174 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:44,174 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:44,174 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:44,175 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:44,175 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:44,175 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:44,176 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:44,176 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:44,176 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:44,177 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:44,177 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:44,166 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:44,188 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:44,188 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:44,194 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:44,194 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:44,195 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:44,195 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:44,196 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:44,196 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:44,199 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:44,199 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:44,201 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-01-17T14:50:44,201 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-01-17T14:50:44,208 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:44,208 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:44,208 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:44,208 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:45,355 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:45,356 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]3824
2022-01-17T14:50:45,356 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:45,356 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:45,356 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:45,356 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:45,357 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:45,357 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:45,359 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427445359
2022-01-17T14:50:45,359 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427445359
2022-01-17T14:50:45,359 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:50:45,360 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:45,617 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:45,618 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:45,618 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:45,618 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:45,619 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:45,619 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:45,619 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:45,619 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:45,620 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:45,620 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:45,620 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:45,620 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:45,621 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:45,621 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:45,621 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:45,622 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:45,619 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:45,622 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:45,622 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:45,622 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:45,623 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:45,622 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:45,624 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:45,623 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:45,624 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:45,625 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:45,625 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:45,625 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:45,625 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:45,626 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:45,624 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:45,627 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:45,626 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:45,627 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:45,627 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:45,627 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:45,627 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:45,627 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:45,628 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:45,628 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:45,628 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:45,629 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-17T14:50:45,629 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:45,629 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-17T14:50:45,629 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:45,633 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:45,633 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:51,941 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:51,941 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:50:52,019 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:52,019 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:50:52,209 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:52,209 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:50:53,635 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:53,635 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:50:54,823 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:54,824 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]5192
2022-01-17T14:50:54,824 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:54,824 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:54,825 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:54,825 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:54,826 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:54,826 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:50:54,827 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:50:54,830 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427454830
2022-01-17T14:50:54,830 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427454830
2022-01-17T14:50:54,832 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:54,928 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:54,930 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]1384
2022-01-17T14:50:54,930 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:54,930 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:54,930 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:54,930 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:54,931 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:54,931 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:50:54,933 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427454933
2022-01-17T14:50:54,933 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427454933
2022-01-17T14:50:54,933 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:50:54,934 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:55,189 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:55,190 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:55,190 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:55,190 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:55,190 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:55,191 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:55,191 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:55,191 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:55,191 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:55,192 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:55,192 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:55,192 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:55,193 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:55,193 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:55,193 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:55,194 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:55,194 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:55,194 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:55,194 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:55,195 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:55,195 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:55,195 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:55,195 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:55,196 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:55,196 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:55,196 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:55,197 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:55,197 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:55,198 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:55,198 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:55,198 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:55,198 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:55,199 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:55,199 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:55,199 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:55,200 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:55,200 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:55,200 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:55,201 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:55,201 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:55,201 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:55,202 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:55,202 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:55,202 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:55,191 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:55,207 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:55,207 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:55,212 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:55,212 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:55,218 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:55,218 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:55,228 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,228 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,237 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,240 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,240 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,237 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,240 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,240 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,242 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-01-17T14:50:55,242 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-01-17T14:50:55,350 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:55,349 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:55,350 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:55,350 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:55,351 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:55,351 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:55,351 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:55,351 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:55,352 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:55,352 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:55,352 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:55,353 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:55,353 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:55,353 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:55,353 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:55,354 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:55,354 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:55,354 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:55,355 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:55,355 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:55,355 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:55,355 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:55,356 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:55,356 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:55,356 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:55,357 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:55,357 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:55,357 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:55,358 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:55,358 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:55,359 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:55,359 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:55,360 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:55,360 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:55,360 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:55,361 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:55,361 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:55,361 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:55,362 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:55,362 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:55,363 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:55,363 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:55,364 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:55,365 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:55,351 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:55,365 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:55,365 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:55,367 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:55,367 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:55,367 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:55,367 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:55,368 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,368 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,368 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,368 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,369 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-01-17T14:50:55,369 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-01-17T14:50:55,377 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,377 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,377 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,377 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,383 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:55,385 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22052
2022-01-17T14:50:55,386 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:55,386 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:55,386 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:55,387 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:55,388 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:55,388 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:50:55,391 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427455391
2022-01-17T14:50:55,391 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427455391
2022-01-17T14:50:55,391 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:50:55,393 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:55,671 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:55,671 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:55,671 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:55,672 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:55,673 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:55,672 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:55,673 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:55,674 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:55,674 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:55,674 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:55,674 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:55,675 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:55,675 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:55,675 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:55,676 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:55,676 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:55,676 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:55,677 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:55,677 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:55,677 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:55,677 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:55,678 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:55,678 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:55,678 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:55,679 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:55,679 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:55,679 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:55,680 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:55,680 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:55,680 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:55,681 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:55,681 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:55,681 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:55,682 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:55,682 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:55,682 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:55,683 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:55,683 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:55,683 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:55,684 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:55,684 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:55,684 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:55,685 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:55,685 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:55,673 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:55,686 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:55,686 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:55,689 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:55,689 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:55,695 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:55,695 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:55,701 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,701 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,703 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,703 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,704 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-01-17T14:50:55,704 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-01-17T14:50:55,707 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,707 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:50:55,711 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:55,711 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:50:56,753 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:50:56,754 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]4208
2022-01-17T14:50:56,755 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:56,755 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:50:56,755 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:50:56,755 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:50:56,756 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:56,756 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:50:56,758 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427456758
2022-01-17T14:50:56,758 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:50:56,758 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427456758
2022-01-17T14:50:56,760 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:50:57,015 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:50:57,016 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:57,016 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:57,016 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:50:57,016 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:50:57,017 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:50:57,017 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:57,017 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:50:57,018 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:50:57,018 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:57,018 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:57,018 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:57,019 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:57,019 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:50:57,019 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:50:57,020 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:57,020 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:50:57,020 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:50:57,021 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:50:57,021 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:50:57,021 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:50:57,021 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:50:57,022 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:50:57,022 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:50:57,022 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:50:57,022 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:50:57,023 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:50:57,023 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:50:57,023 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:50:57,024 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:50:57,024 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:50:57,024 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:50:57,025 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:50:57,025 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:50:57,025 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:50:57,025 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:50:57,026 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:50:57,026 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:50:57,026 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:50:57,027 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:50:57,027 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:50:57,027 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:50:57,028 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:50:57,028 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:50:57,017 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:50:57,029 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:57,029 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:50:57,056 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:57,056 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:50:57,072 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:57,072 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:50:57,088 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:57,088 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:57,093 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:57,093 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:57,094 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-17T14:50:57,094 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-17T14:50:57,097 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:57,097 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:50:57,097 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:50:57,097 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:51:08,244 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:51:08,244 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:51:08,371 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:51:08,371 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:51:08,720 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:51:08,720 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:51:10,100 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:51:10,100 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:51:11,133 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:51:11,134 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]3436
2022-01-17T14:51:11,134 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:51:11,134 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:51:11,134 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:11,134 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:11,135 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:51:11,135 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:51:11,145 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:51:11,149 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427471149
2022-01-17T14:51:11,149 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427471149
2022-01-17T14:51:11,151 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:51:11,334 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427471
2022-01-17T14:51:11,335 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:75.18249130249023|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427471
2022-01-17T14:51:11,336 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:371.5040283203125|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427471
2022-01-17T14:51:11,336 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:83.2|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427471
2022-01-17T14:51:11,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:655.69140625|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427471
2022-01-17T14:51:11,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7419.06640625|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427471
2022-01-17T14:51:11,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:91.9|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427471
2022-01-17T14:51:11,402 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=22052)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 22052

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('22052',)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('22052', 0)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=1384)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 1384

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('1384',)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('1384', 0)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=5192)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 5192

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('5192',)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('5192', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='cp1252'>
OSError: [Errno 22] Invalid argument

2022-01-17T14:51:11,402 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=22052)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 22052

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('22052',)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('22052', 0)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=1384)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 1384

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('1384',)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('1384', 0)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=5192)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 5192

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('5192',)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1087, in emit
    self.flush()
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\logging\__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\metrics\metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('5192', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='cp1252'>
OSError: [Errno 22] Invalid argument

2022-01-17T14:51:11,473 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:51:11,474 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]21172
2022-01-17T14:51:11,475 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:11,475 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:51:11,475 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:11,475 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:51:11,475 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:51:11,476 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:51:11,477 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427471477
2022-01-17T14:51:11,477 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427471477
2022-01-17T14:51:11,477 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:51:11,478 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:51:11,743 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:11,743 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:51:11,743 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:11,743 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:11,744 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:51:11,744 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:11,744 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:51:11,744 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:11,745 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:51:11,748 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:51:11,748 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:11,748 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:11,749 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:11,749 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:11,750 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:51:11,750 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:51:11,750 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:11,751 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:51:11,751 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:11,751 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:11,751 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:51:11,752 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:51:11,752 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:51:11,752 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:51:11,753 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:51:11,753 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:51:11,753 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:51:11,753 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:51:11,754 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:51:11,754 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:51:11,754 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:51:11,755 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:51:11,755 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:11,756 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:11,756 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:11,756 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:11,757 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:51:11,757 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:51:11,757 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:51:11,758 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:51:11,758 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:51:11,758 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:51:11,759 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:51:11,759 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:51:11,759 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:51:11,747 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:11,747 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:11,791 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:11,791 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:11,801 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:11,801 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:11,803 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:51:11,803 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:51:11,804 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:51:11,804 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:51:11,808 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-01-17T14:51:11,808 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-01-17T14:51:11,815 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:51:11,815 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:51:11,815 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:51:11,815 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:51:11,928 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:11,927 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:51:11,928 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:11,928 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:11,929 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:51:11,929 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:11,929 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:51:11,929 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:51:11,930 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:51:11,930 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:11,930 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:11,930 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:11,931 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:11,931 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:51:11,932 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:51:11,932 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:11,932 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:51:11,932 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:11,933 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:11,933 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:51:11,933 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:51:11,934 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:51:11,934 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:51:11,934 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:51:11,935 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:51:11,935 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:51:11,935 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:51:11,935 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:51:11,936 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:51:11,936 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:51:11,936 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:51:11,937 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:11,937 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:11,937 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:11,938 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:11,939 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:51:11,939 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:51:11,939 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:51:11,939 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:51:11,940 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:51:11,940 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:51:11,940 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:51:11,941 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:51:11,941 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:51:11,929 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:11,946 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:11,946 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:11,948 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:11,948 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:11,949 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:11,949 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:11,949 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:51:11,949 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:51:11,950 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:51:11,950 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:51:11,950 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-01-17T14:51:11,950 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-01-17T14:51:11,956 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:51:11,956 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:51:11,956 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:51:11,956 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:51:12,027 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:51:12,028 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22424
2022-01-17T14:51:12,028 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:12,028 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:51:12,028 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:51:12,028 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:12,029 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:51:12,029 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:51:12,032 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:51:12,033 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427472033
2022-01-17T14:51:12,033 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427472033
2022-01-17T14:51:12,035 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:51:12,310 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:12,309 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:51:12,310 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:12,310 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:12,311 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:12,311 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:51:12,311 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:51:12,312 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:51:12,312 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:51:12,312 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:12,313 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:12,313 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:12,313 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:12,314 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:51:12,314 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:51:12,314 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:12,314 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:51:12,315 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:12,315 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:12,315 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:51:12,315 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:51:12,316 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:51:12,316 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:51:12,316 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:51:12,317 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:51:12,317 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:51:12,317 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:51:12,318 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:51:12,318 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:51:12,318 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:51:12,319 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:51:12,319 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:12,319 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:12,320 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:12,320 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:12,320 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:51:12,321 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:51:12,321 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:51:12,322 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:51:12,311 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:12,322 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:51:12,323 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:51:12,323 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:12,323 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:51:12,324 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:51:12,324 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:51:12,323 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:12,331 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:12,331 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:12,335 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:12,335 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:12,339 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:51:12,339 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:51:12,340 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:51:12,340 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:51:12,341 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-01-17T14:51:12,341 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-01-17T14:51:12,344 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:51:12,344 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:51:12,344 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:51:12,344 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:51:13,458 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:51:13,459 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]17060
2022-01-17T14:51:13,459 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:13,459 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:51:13,459 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:13,460 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:51:13,459 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:51:13,460 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:51:13,462 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427473462
2022-01-17T14:51:13,462 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427473462
2022-01-17T14:51:13,462 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:51:13,463 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:51:13,724 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:13,723 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:51:13,724 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:13,724 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:13,725 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:13,724 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:51:13,725 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:51:13,725 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:51:13,725 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:51:13,726 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:13,726 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:13,725 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:13,726 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:13,727 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:13,727 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:13,727 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:51:13,727 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:51:13,728 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:13,728 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:51:13,728 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:13,728 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:13,729 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:51:13,729 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:51:13,729 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:51:13,729 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:51:13,730 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:51:13,727 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:13,730 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:51:13,731 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:51:13,732 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:13,732 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:51:13,732 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:51:13,732 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:51:13,732 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:13,733 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:51:13,739 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:51:13,739 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:13,739 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:13,740 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:13,740 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:13,741 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:13,741 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:51:13,741 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:51:13,742 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:51:13,742 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:51:13,742 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:51:13,743 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:51:13,743 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:51:13,743 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:51:13,744 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:51:13,739 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:13,747 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:51:13,747 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:51:13,748 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:51:13,748 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:51:13,748 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-17T14:51:13,748 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-17T14:51:13,751 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:51:13,751 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:51:13,751 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:51:13,751 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:51:32,822 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:51:32,822 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:51:32,965 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:51:32,965 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:51:33,349 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:51:33,349 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:51:34,761 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:51:34,761 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:51:35,966 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:51:35,968 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]13260
2022-01-17T14:51:35,970 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:51:35,971 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:35,971 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:35,972 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:51:35,972 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:51:35,973 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427495973
2022-01-17T14:51:35,973 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427495973
2022-01-17T14:51:35,975 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:51:35,976 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:51:35,982 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:51:35,999 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:51:36,000 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]7476
2022-01-17T14:51:36,000 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:51:36,001 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:36,001 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:36,001 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:51:36,001 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:51:36,002 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:51:36,003 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:51:36,004 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427496004
2022-01-17T14:51:36,004 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427496004
2022-01-17T14:51:36,005 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:51:36,422 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:51:36,422 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:36,422 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:36,422 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:36,422 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:51:36,423 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:36,423 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:51:36,423 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:51:36,423 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:51:36,424 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:36,424 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:36,424 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:36,425 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:36,425 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:51:36,425 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:51:36,426 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:36,426 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:51:36,426 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:36,426 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:36,427 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:51:36,427 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:51:36,427 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:51:36,427 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:51:36,428 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:51:36,428 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:51:36,429 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:51:36,429 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:51:36,429 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:51:36,429 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:51:36,430 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:51:36,430 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:51:36,430 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:36,431 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:36,431 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:36,432 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:36,432 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:51:36,433 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:51:36,433 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:51:36,433 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:51:36,433 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:51:36,434 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:51:36,434 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:51:36,434 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:51:36,435 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:51:36,456 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:36,456 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:36,456 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:51:36,478 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:36,478 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:36,478 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:51:36,479 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:51:36,480 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:51:36,480 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:51:36,480 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:36,481 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:36,481 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:36,481 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:36,481 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:51:36,482 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:51:36,482 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:36,423 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:36,482 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:51:36,483 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:36,483 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:36,483 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:51:36,483 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:51:36,484 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:51:36,484 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:51:36,484 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:51:36,484 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:51:36,485 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:51:36,485 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:51:36,485 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:51:36,486 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:51:36,486 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:51:36,486 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:51:36,487 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:36,487 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:36,487 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:36,488 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:36,488 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:51:36,488 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:51:36,489 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:51:36,489 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:51:36,489 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:51:36,490 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:51:36,490 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:51:36,490 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:51:36,490 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:51:36,482 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:36,478 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:36,513 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:36,513 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:36,534 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:36,482 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:36,535 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:36,534 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:36,535 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:36,535 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:36,535 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:36,539 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:51:36,540 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:36,539 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:51:36,551 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:51:36,551 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:51:36,540 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:36,562 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:51:36,562 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:51:36,562 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:51:36,562 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:51:36,562 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:51:36,562 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:51:36,564 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:51:36,565 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2022-01-17T14:51:36,564 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:51:36,570 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2022-01-17T14:51:36,570 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2022-01-17T14:51:36,565 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2022-01-17T14:51:36,577 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:51:36,577 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:51:36,577 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:51:36,577 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:51:36,725 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:51:36,726 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22160
2022-01-17T14:51:36,727 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:36,727 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:51:36,727 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:51:36,727 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:36,728 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:51:36,728 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:51:36,731 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:51:36,731 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427496731
2022-01-17T14:51:36,731 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427496731
2022-01-17T14:51:36,732 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:51:37,053 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:37,052 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:51:37,053 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:37,053 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:37,054 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:51:37,054 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:51:37,055 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:51:37,055 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:51:37,055 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:37,055 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:37,056 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:37,056 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:37,056 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:37,057 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:51:37,057 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:51:37,057 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:37,057 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:51:37,058 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:37,058 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:37,058 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:51:37,058 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:51:37,059 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:51:37,059 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:51:37,059 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:51:37,059 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:51:37,060 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:51:37,060 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:51:37,060 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:51:37,061 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:51:37,061 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:51:37,061 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:51:37,062 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:37,062 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:37,062 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:37,063 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:37,063 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:51:37,063 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:51:37,064 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:51:37,064 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:51:37,064 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:51:37,065 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:51:37,065 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:51:37,065 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:51:37,065 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:51:37,055 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:37,068 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:37,068 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:37,071 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:37,071 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:37,071 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:37,071 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:37,073 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:51:37,073 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:51:37,073 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:51:37,073 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:51:37,074 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2022-01-17T14:51:37,074 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2022-01-17T14:51:37,082 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:51:37,082 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:51:37,082 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:51:37,082 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:51:38,229 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:51:38,230 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]11288
2022-01-17T14:51:38,230 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:38,230 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:51:38,231 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:51:38,230 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:51:38,231 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:51:38,231 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:51:38,234 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427498234
2022-01-17T14:51:38,234 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:51:38,234 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427498234
2022-01-17T14:51:38,236 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:51:38,523 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:51:38,523 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:38,523 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:51:38,523 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:38,524 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:51:38,524 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:51:38,524 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:38,524 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:51:38,525 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:51:38,525 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:38,525 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:38,526 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:38,526 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:38,526 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:51:38,527 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:51:38,527 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:38,527 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:51:38,527 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:51:38,528 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:51:38,528 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:51:38,528 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:51:38,528 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:51:38,529 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:51:38,529 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:51:38,529 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:51:38,529 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:51:38,530 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:51:38,530 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:51:38,530 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:51:38,531 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:51:38,531 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:51:38,531 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:51:38,532 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:51:38,532 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:51:38,532 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:51:38,532 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:51:38,533 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:51:38,533 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:51:38,533 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:51:38,534 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:51:38,534 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:51:38,534 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:51:38,534 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:51:38,535 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:51:38,524 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:51:38,535 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:38,535 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:51:38,537 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:38,537 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:51:38,538 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:38,538 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:51:38,538 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:51:38,538 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:51:38,539 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:51:38,539 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:51:38,540 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-17T14:51:38,540 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-17T14:51:38,543 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:51:38,543 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:51:38,543 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:51:38,543 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:52:10,575 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:52:10,575 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:52:10,575 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:52:10,575 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:52:11,084 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:52:11,084 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:52:12,553 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:52:12,553 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:52:13,482 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:52:13,483 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]23064
2022-01-17T14:52:13,483 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:52:13,483 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:52:13,484 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:52:13,483 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:52:13,485 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:52:13,485 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:52:13,486 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:52:13,487 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427533487
2022-01-17T14:52:13,487 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427533487
2022-01-17T14:52:13,489 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:52:13,521 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:52:13,522 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]22972
2022-01-17T14:52:13,523 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:52:13,523 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:52:13,523 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:52:13,524 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:52:13,524 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:52:13,524 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:52:13,527 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427533527
2022-01-17T14:52:13,527 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427533527
2022-01-17T14:52:13,531 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:52:13,531 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:52:13,891 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:52:13,892 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:52:13,892 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-01-17T14:52:13,892 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:52:13,892 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:52:13,893 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:52:13,893 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:52:13,893 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:52:13,894 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:52:13,894 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:52:13,894 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:52:13,894 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:52:13,896 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:52:13,897 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:52:13,897 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:52:13,896 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:52:13,897 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:52:13,898 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:52:13,898 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:52:13,898 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:52:13,898 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:52:13,899 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:52:13,899 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:52:13,899 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:52:13,900 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:52:13,900 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:52:13,900 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:52:13,900 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:52:13,901 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:52:13,901 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:52:13,901 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:52:13,902 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:52:13,902 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:52:13,902 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:52:13,903 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:52:13,903 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:52:13,903 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:52:13,904 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:52:13,904 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:52:13,904 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:52:13,904 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:52:13,905 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:52:13,905 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:52:13,905 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:52:13,906 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:52:13,906 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:52:13,896 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:52:13,909 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:52:13,909 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:52:13,924 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:52:13,929 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:52:13,924 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:52:13,929 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-17T14:52:13,928 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:52:13,949 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:52:13,949 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:52:13,949 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:52:13,950 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:52:13,950 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:52:13,950 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:52:13,951 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:52:13,951 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:52:13,951 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:52:13,949 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:52:13,952 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:52:13,952 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:52:13,952 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:52:13,952 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:52:13,953 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:52:13,953 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:52:13,955 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:52:13,952 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:52:13,955 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:52:13,963 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:52:13,963 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:52:13,953 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:52:13,963 [WARN ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:52:13,963 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2022-01-17T14:52:13,963 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:52:13,963 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2022-01-17T14:52:13,963 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:52:13,964 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:52:13,963 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:52:13,964 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:52:13,964 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:52:13,964 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:52:13,964 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:52:13,965 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:52:13,964 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:52:13,965 [WARN ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:52:13,965 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2022-01-17T14:52:13,965 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:52:13,965 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:52:13,969 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:52:13,969 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:52:13,997 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:52:13,965 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2022-01-17T14:52:13,997 [INFO ] W-9001-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stderr
2022-01-17T14:52:13,969 [INFO ] W-9002-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stderr
2022-01-17T14:52:13,969 [INFO ] W-9002-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_fancy_model_1.0-stdout
2022-01-17T14:52:13,965 [INFO ] W-9001-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_fancy_model_1.0-stdout
2022-01-17T14:52:14,453 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:52:14,453 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]9836
2022-01-17T14:52:14,454 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:52:14,454 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:52:14,454 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:52:14,454 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:52:14,455 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:52:14,455 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:52:14,456 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427534456
2022-01-17T14:52:14,456 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427534456
2022-01-17T14:52:14,456 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:52:14,458 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:52:14,738 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:52:14,738 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:52:14,738 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:52:14,738 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-01-17T14:52:14,738 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:52:14,739 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:52:14,739 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:52:14,739 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:52:14,740 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:52:14,740 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:52:14,740 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:52:14,741 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:52:14,741 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:52:14,741 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:52:14,742 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:52:14,742 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:52:14,742 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:52:14,739 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:52:14,743 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:52:14,743 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:52:14,743 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:52:14,743 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:52:14,743 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:52:14,744 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:52:14,744 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:52:14,744 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:52:14,745 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:52:14,745 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:52:14,745 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:52:14,745 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:52:14,746 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:52:14,746 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:52:14,746 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:52:14,747 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:52:14,747 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:52:14,747 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:52:14,747 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:52:14,748 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:52:14,748 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:52:14,748 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:52:14,749 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:52:14,749 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:52:14,749 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:52:14,750 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:52:14,750 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:52:14,750 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:52:14,743 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:52:14,752 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:52:14,752 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:52:14,780 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:52:14,780 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:52:14,785 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:52:14,785 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:52:14,788 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:52:14,790 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:52:14,790 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:52:14,788 [WARN ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:52:14,791 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2022-01-17T14:52:14,790 [INFO ] W-9003-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stdout
2022-01-17T14:52:14,790 [INFO ] W-9003-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_fancy_model_1.0-stderr
2022-01-17T14:52:14,791 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2022-01-17T14:52:15,768 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:52:15,769 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]19956
2022-01-17T14:52:15,770 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:52:15,770 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:52:15,770 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:52:15,770 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-17T14:52:15,771 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:52:15,771 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:52:15,772 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427535772
2022-01-17T14:52:15,772 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427535772
2022-01-17T14:52:15,772 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:52:15,774 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:52:16,040 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-17T14:52:16,041 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:52:16,041 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:52:16,041 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-17T14:52:16,041 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-17T14:52:16,042 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:52:16,042 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-17T14:52:16,042 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-17T14:52:16,043 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-17T14:52:16,043 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:52:16,043 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:52:16,044 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:52:16,044 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:52:16,044 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-01-17T14:52:16,045 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2022-01-17T14:52:16,045 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:52:16,045 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-01-17T14:52:16,045 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - 
2022-01-17T14:52:16,046 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-17T14:52:16,046 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-17T14:52:16,046 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-17T14:52:16,046 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-17T14:52:16,047 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-17T14:52:16,047 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-17T14:52:16,047 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-17T14:52:16,047 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-17T14:52:16,048 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-17T14:52:16,048 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 85, in load
2022-01-17T14:52:16,048 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-01-17T14:52:16,048 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\model_loader.py", line 128, in _load_default_handler
2022-01-17T14:52:16,049 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-01-17T14:52:16,049 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\importlib\__init__.py", line 127, in import_module
2022-01-17T14:52:16,049 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-17T14:52:16,050 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-01-17T14:52:16,050 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-01-17T14:52:16,050 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-01-17T14:52:16,051 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-01-17T14:52:16,051 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-01-17T14:52:16,051 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-01-17T14:52:16,051 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\image_classifier.py", line 8, in <module>
2022-01-17T14:52:16,052 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from .vision_handler import VisionHandler
2022-01-17T14:52:16,052 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -   File "C:\Users\Garsdal\Anaconda3\envs\env_DL\lib\site-packages\ts\torch_handler\vision_handler.py", line 11, in <module>
2022-01-17T14:52:16,052 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG -     from captum.attr import IntegratedGradients
2022-01-17T14:52:16,053 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'captum'
2022-01-17T14:52:16,042 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-17T14:52:16,055 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:52:16,055 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-17T14:52:16,057 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:52:16,057 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_fancy_model, error: Worker died.
2022-01-17T14:52:16,058 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:52:16,058 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-17T14:52:16,059 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:52:16,059 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:52:16,059 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:52:16,059 [WARN ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:52:16,060 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-17T14:52:16,060 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-17T14:52:16,064 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:52:16,064 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:52:16,064 [INFO ] W-9000-my_fancy_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stdout
2022-01-17T14:52:16,064 [INFO ] W-9000-my_fancy_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_fancy_model_1.0-stderr
2022-01-17T14:54:08,820 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:54:08,820 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-17T14:54:09,066 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: my_fancy_model=my_fancy_model.mar
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:54:09,066 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages
Current directory: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6
Temp directory: C:\Users\Garsdal\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 2020 M
Python executable: C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Initial Models: my_fancy_model=my_fancy_model.mar
Log dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Metrics dir: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\Garsdal\Documents\GitHub\mlops_exercises\day_6\model_store
Model config: N/A
2022-01-17T14:54:09,082 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:54:09,082 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-17T14:54:09,120 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: my_fancy_model.mar
2022-01-17T14:54:09,120 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: my_fancy_model.mar
2022-01-17T14:54:10,643 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_fancy_model
2022-01-17T14:54:10,643 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_fancy_model
2022-01-17T14:54:10,645 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_fancy_model
2022-01-17T14:54:10,645 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_fancy_model
2022-01-17T14:54:10,645 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_fancy_model loaded.
2022-01-17T14:54:10,645 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_fancy_model loaded.
2022-01-17T14:54:10,646 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_fancy_model, count: 4
2022-01-17T14:54:10,646 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_fancy_model, count: 4
2022-01-17T14:54:10,662 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:54:10,665 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:54:10,662 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-01-17T14:54:10,665 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-01-17T14:54:10,668 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:54:10,668 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-17T14:54:10,677 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:54:10,677 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-01-17T14:54:10,691 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:54:10,691 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\Garsdal\Anaconda3\envs\env_DL\python.exe, C:\Users\Garsdal\Anaconda3\envs\env_DL\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-17T14:54:11,313 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:54:11,313 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-17T14:54:11,314 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:54:11,314 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-17T14:54:11,316 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:54:11,316 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-17T14:54:11,317 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:54:11,317 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-17T14:54:11,318 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:54:11,318 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-17T14:54:11,993 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-17T14:54:11,993 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-17T14:54:12,707 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427652
2022-01-17T14:54:12,716 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:75.16919326782227|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427652
2022-01-17T14:54:12,717 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:371.51732635498047|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427652
2022-01-17T14:54:12,718 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:83.2|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427652
2022-01-17T14:54:12,719 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1017.65234375|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427652
2022-01-17T14:54:12,719 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7057.109375|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427652
2022-01-17T14:54:12,720 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:87.4|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427652
2022-01-17T14:54:14,291 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:54:14,293 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - [PID]6748
2022-01-17T14:54:14,294 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:54:14,294 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:54:14,295 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:54:14,295 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:54:14,301 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:54:14,301 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-17T14:54:14,316 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-17T14:54:14,324 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427654324
2022-01-17T14:54:14,324 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427654324
2022-01-17T14:54:14,367 [INFO ] W-9000-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:54:14,375 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:54:14,377 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - [PID]17692
2022-01-17T14:54:14,377 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:54:14,377 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:54:14,378 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:54:14,377 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:54:14,388 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:54:14,388 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-01-17T14:54:14,393 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427654393
2022-01-17T14:54:14,393 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-01-17T14:54:14,393 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427654393
2022-01-17T14:54:14,419 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:54:14,541 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:54:14,543 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - [PID]5664
2022-01-17T14:54:14,543 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:54:14,543 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:54:14,543 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:54:14,544 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:54:14,547 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:54:14,547 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-01-17T14:54:14,550 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427654550
2022-01-17T14:54:14,550 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427654550
2022-01-17T14:54:14,550 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-01-17T14:54:14,571 [INFO ] W-9002-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:54:14,788 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-17T14:54:14,789 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - [PID]5188
2022-01-17T14:54:14,789 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-17T14:54:14,790 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:54:14,790 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-01-17T14:54:14,790 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change null -> WORKER_STARTED
2022-01-17T14:54:14,791 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:54:14,791 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-01-17T14:54:14,794 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-01-17T14:54:14,795 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427654795
2022-01-17T14:54:14,795 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427654795
2022-01-17T14:54:14,832 [INFO ] W-9001-my_fancy_model_1.0-stdout MODEL_LOG - model_name: my_fancy_model, batchSize: 1
2022-01-17T14:54:17,397 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2978
2022-01-17T14:54:17,397 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2978
2022-01-17T14:54:17,398 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-17T14:54:17,398 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-17T14:54:17,399 [INFO ] W-9003-my_fancy_model_1.0 TS_METRICS - W-9003-my_fancy_model_1.0.ms:6742|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427657
2022-01-17T14:54:17,400 [INFO ] W-9003-my_fancy_model_1.0 TS_METRICS - WorkerThreadTime.ms:29|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:null
2022-01-17T14:54:17,550 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3183
2022-01-17T14:54:17,550 [INFO ] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3183
2022-01-17T14:54:17,551 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-17T14:54:17,551 [DEBUG] W-9000-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-17T14:54:17,551 [INFO ] W-9000-my_fancy_model_1.0 TS_METRICS - W-9000-my_fancy_model_1.0.ms:6896|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427657
2022-01-17T14:54:17,552 [INFO ] W-9000-my_fancy_model_1.0 TS_METRICS - WorkerThreadTime.ms:45|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:null
2022-01-17T14:54:17,609 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3038
2022-01-17T14:54:17,609 [INFO ] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3038
2022-01-17T14:54:17,609 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-17T14:54:17,609 [DEBUG] W-9002-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-17T14:54:17,610 [INFO ] W-9002-my_fancy_model_1.0 TS_METRICS - W-9002-my_fancy_model_1.0.ms:6953|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427657
2022-01-17T14:54:17,611 [INFO ] W-9002-my_fancy_model_1.0 TS_METRICS - WorkerThreadTime.ms:23|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:null
2022-01-17T14:54:17,801 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2968
2022-01-17T14:54:17,801 [INFO ] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2968
2022-01-17T14:54:17,802 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-17T14:54:17,802 [DEBUG] W-9001-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_fancy_model_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-17T14:54:17,803 [INFO ] W-9001-my_fancy_model_1.0 TS_METRICS - W-9001-my_fancy_model_1.0.ms:7146|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427657
2022-01-17T14:54:17,804 [INFO ] W-9001-my_fancy_model_1.0 TS_METRICS - WorkerThreadTime.ms:41|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:null
2022-01-17T14:54:57,922 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427697922
2022-01-17T14:54:57,922 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642427697922
2022-01-17T14:54:57,925 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_LOG - Backend received inference at: 1642427697
2022-01-17T14:54:58,262 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 338
2022-01-17T14:54:58,262 [INFO ] W-9003-my_fancy_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 338
2022-01-17T14:54:58,262 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:337.75|#ModelName:my_fancy_model,Level:Model|#hostname:LAPTOP-0LT5I2J5,requestID:fa557d5f-2cfb-4942-aa40-440f3991c63f,timestamp:1642427698
2022-01-17T14:54:58,263 [INFO ] W-9003-my_fancy_model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:337.75|#ModelName:my_fancy_model,Level:Model|#hostname:LAPTOP-0LT5I2J5,requestID:fa557d5f-2cfb-4942-aa40-440f3991c63f,timestamp:1642427698
2022-01-17T14:54:58,264 [INFO ] W-9003-my_fancy_model_1.0 ACCESS_LOG - /127.0.0.1:63545 "PUT /predictions/my_fancy_model HTTP/1.1" 200 354
2022-01-17T14:54:58,265 [INFO ] W-9003-my_fancy_model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:null
2022-01-17T14:54:58,267 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.job.Job - Waiting time ns: 171800, Backend time ns: 345151500
2022-01-17T14:54:58,267 [DEBUG] W-9003-my_fancy_model_1.0 org.pytorch.serve.job.Job - Waiting time ns: 171800, Backend time ns: 345151500
2022-01-17T14:54:58,268 [INFO ] W-9003-my_fancy_model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:null
2022-01-17T14:54:58,272 [INFO ] W-9003-my_fancy_model_1.0 TS_METRICS - WorkerThreadTime.ms:12|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:null
2022-01-17T14:55:12,185 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427712
2022-01-17T14:55:12,186 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:75.16876602172852|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427712
2022-01-17T14:55:12,187 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:371.5177536010742|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427712
2022-01-17T14:55:12,188 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:83.2|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427712
2022-01-17T14:55:12,189 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:496.625|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427712
2022-01-17T14:55:12,189 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7578.1328125|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427712
2022-01-17T14:55:12,190 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:93.8|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427712
2022-01-17T14:56:12,184 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427772
2022-01-17T14:56:12,185 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:75.16623306274414|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427772
2022-01-17T14:56:12,186 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:371.5202865600586|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427772
2022-01-17T14:56:12,188 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:83.2|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427772
2022-01-17T14:56:12,188 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:548.07421875|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427772
2022-01-17T14:56:12,188 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7526.68359375|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427772
2022-01-17T14:56:12,188 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:93.2|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427772
2022-01-17T14:57:12,204 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427832
2022-01-17T14:57:12,205 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:75.17184448242188|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427832
2022-01-17T14:57:12,206 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:371.51467514038086|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427832
2022-01-17T14:57:12,206 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:83.2|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427832
2022-01-17T14:57:12,207 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:557.890625|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427832
2022-01-17T14:57:12,208 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7516.8671875|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427832
2022-01-17T14:57:12,209 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:93.1|#Level:Host|#hostname:LAPTOP-0LT5I2J5,timestamp:1642427832
